{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZwQc8iIYzhL"
   },
   "source": [
    "# MIS780 Advanced AI For Business - Assignment 2 - T2 2022\n",
    "\n",
    "## Example 1:  Multilayer Perceptron - Diabetes Classification Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LocH583hYzhR"
   },
   "source": [
    "**Student Name:** Pranitha Gaddam\n",
    "\n",
    "**Student ID:** 221183244"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QoBihZe6_Acd"
   },
   "source": [
    "## Table of Content\n",
    "   \n",
    "1. [Data Description](#cell_Preparation)\n",
    "\n",
    "2. [Data Preprocessing](#cell_Preprocessing)\n",
    "\n",
    "3. [Model Construction](#cell_model)\n",
    "\n",
    "4. [Model Execution](#cell_execution)\n",
    " \n",
    "5. [Experiments Report](#cell_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzo8kho_wzib"
   },
   "source": [
    "## Executive Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_D-HpoG7w1YP"
   },
   "source": [
    "The objective of conducting a neural network model analysis on the dataset is to diagnostically predict whether or not a patient has diabetes. The dataset \"Pima Indians Diabetes Database\" has been acquired from Kaggle. This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases.The proposed model applied in this instance is Multilayer Perceptron using Keras package. MLP's are feedforward NN which help in classification of dataset, be it binary or multiple classes. MLPs are useful in their research for solving problems stochastically which often allows approximate solutions for extremely complex problems. Moreover, in order to improve the accuracy score, we can interchange the number of neurons in the layers which produces a classification score. The perceptron learns a decision boundary on a graph that separates two classes using a line (called a hyperplane) in the feature space, and thus produces an output. \n",
    "\n",
    "We conduct analysis by first cleaning the dataset and dropping any null values. Followed by, standardisation of the dataset and splitting the dataset into Test and Train set. We then construct the MLP model and execute it by fitting the training set to see if it overfits with the test set. We then perform prediction on the test dataset to get the accuracy score determining whether the model has performed well or not, implying how well can the model predict whether a patient has diabetes or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufoVVdqtYzhU"
   },
   "source": [
    "<a id = \"cell_Preparation\"></a>\n",
    "## 1. Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njDKx1_JYzhU"
   },
   "source": [
    "The dataset has 8 medical predictor (independent) variables namely : Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, DiabetesPedigreeFunction, Age and one target variable 'Outcome' that will help determine whether a person has diabetes. The dataset has the shape of 768 rows and 9 columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aV98C_LtNf1p",
    "outputId": "95f96362-2b6a-4aea-f949-95298a705afc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#mount drive to import the dataset\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bED5DRbnOL_m"
   },
   "outputs": [],
   "source": [
    "#import the necessary packages\n",
    "import numpy as np \n",
    "from keras.models import Sequential \n",
    "from keras.layers import LSTM \n",
    "from keras.layers import Dense, Dropout \n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Mp1qj8eNsWF"
   },
   "outputs": [],
   "source": [
    "D = pd.read_csv('/content/drive/MyDrive/MIS780/diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "WRUNIB82NsRL",
    "outputId": "d86f4a66-8f6e-4fa3-be23-f2f226deb819"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-0fd3dd00-b8ff-4acc-81aa-48c4fd39ebdb\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0fd3dd00-b8ff-4acc-81aa-48c4fd39ebdb')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-0fd3dd00-b8ff-4acc-81aa-48c4fd39ebdb button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-0fd3dd00-b8ff-4acc-81aa-48c4fd39ebdb');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EhWXZvChNsHq",
    "outputId": "55cb5083-803f-4090-a456-b6d1c0ba84ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vi0DClinOpRh"
   },
   "outputs": [],
   "source": [
    "#Checking for duplicates and removing any\n",
    "D.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iqZOj2NROzS_",
    "outputId": "10bb05d5-bf39-44b0-ff1d-d86f65304bc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NMGjg4-232B8",
    "outputId": "7b436b51-1063-4269-d860-c2cbee15ed08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 60.0 KB\n"
     ]
    }
   ],
   "source": [
    "D.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqPl5gh_YzhX"
   },
   "source": [
    "<a id = \"cell_Preprocessing\"></a>\n",
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XEIvx87g2M-W",
    "outputId": "83d7054d-472c-4ecc-f22b-19307b7e8946"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
       "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
       "       ...,\n",
       "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
       "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
       "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert the dataset into an array \n",
    "Diabetes = D.values\n",
    "Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b3dBVjrKPLkT"
   },
   "outputs": [],
   "source": [
    "#Get all of the rows from the first eight columns of the dataset \n",
    "X = Diabetes[:, 0:8]\n",
    "y = Diabetes[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xWRJR3YBPLXv",
    "outputId": "facd1463-9d95-4270-ed61-3a2773d74d8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
       "        0.48333333],\n",
       "       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
       "        0.16666667],\n",
       "       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
       "        0.18333333],\n",
       "       ...,\n",
       "       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n",
       "        0.15      ],\n",
       "       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n",
       "        0.43333333],\n",
       "       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n",
       "        0.03333333]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)\n",
    "X_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NFR_85N1Peyp"
   },
   "outputs": [],
   "source": [
    "#Split data into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scale, y , test_size =0.2, random_state = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lY3RPGcKYzhc"
   },
   "source": [
    "<a id = \"cell_model\"></a>\n",
    "## 3. Model Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4CJvLRxSNb3"
   },
   "source": [
    "The model used here is Sequential which consists of three Dense layers. The first Dense layer has three attributes :  15 layers, ReLu activation function and input shape of (8,). The second Dense layer has 15 layers and the last layer has 1 layer. I have used sigmoid activation function since it is a binary classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YRSO49oTYzhc"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(20, activation = 'relu', input_shape = (8,)),\n",
    "    Dense(15, activation = 'relu'),\n",
    "    Dense(1, activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VxeSdKokQ4xJ"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'sgd',\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0h_o6nnufjg"
   },
   "source": [
    "<a id = \"cell_execution\"></a>\n",
    "## 4. Model Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J2fmJxVlyqBp",
    "outputId": "53d710b9-5a27-4683-eab8-1c2da7cd0d40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7058 - accuracy: 0.3523 - val_loss: 0.7020 - val_accuracy: 0.3577\n",
      "Epoch 2/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6982 - accuracy: 0.3605 - val_loss: 0.6950 - val_accuracy: 0.3740\n",
      "Epoch 3/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6918 - accuracy: 0.5275 - val_loss: 0.6890 - val_accuracy: 0.6341\n",
      "Epoch 4/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6863 - accuracy: 0.6517 - val_loss: 0.6838 - val_accuracy: 0.6423\n",
      "Epoch 5/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6815 - accuracy: 0.6721 - val_loss: 0.6792 - val_accuracy: 0.6911\n",
      "Epoch 6/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6774 - accuracy: 0.6538 - val_loss: 0.6753 - val_accuracy: 0.6504\n",
      "Epoch 7/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6738 - accuracy: 0.6619 - val_loss: 0.6718 - val_accuracy: 0.6667\n",
      "Epoch 8/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6705 - accuracy: 0.6517 - val_loss: 0.6686 - val_accuracy: 0.6585\n",
      "Epoch 9/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6677 - accuracy: 0.6477 - val_loss: 0.6658 - val_accuracy: 0.6504\n",
      "Epoch 10/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6651 - accuracy: 0.6477 - val_loss: 0.6633 - val_accuracy: 0.6504\n",
      "Epoch 11/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6628 - accuracy: 0.6477 - val_loss: 0.6611 - val_accuracy: 0.6504\n",
      "Epoch 12/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6608 - accuracy: 0.6477 - val_loss: 0.6591 - val_accuracy: 0.6504\n",
      "Epoch 13/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6590 - accuracy: 0.6477 - val_loss: 0.6573 - val_accuracy: 0.6504\n",
      "Epoch 14/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6574 - accuracy: 0.6477 - val_loss: 0.6558 - val_accuracy: 0.6504\n",
      "Epoch 15/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6560 - accuracy: 0.6477 - val_loss: 0.6544 - val_accuracy: 0.6504\n",
      "Epoch 16/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6548 - accuracy: 0.6477 - val_loss: 0.6531 - val_accuracy: 0.6504\n",
      "Epoch 17/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6536 - accuracy: 0.6477 - val_loss: 0.6520 - val_accuracy: 0.6504\n",
      "Epoch 18/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6526 - accuracy: 0.6477 - val_loss: 0.6510 - val_accuracy: 0.6504\n",
      "Epoch 19/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6517 - accuracy: 0.6477 - val_loss: 0.6501 - val_accuracy: 0.6504\n",
      "Epoch 20/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6508 - accuracy: 0.6477 - val_loss: 0.6493 - val_accuracy: 0.6504\n",
      "Epoch 21/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6502 - accuracy: 0.6477 - val_loss: 0.6486 - val_accuracy: 0.6504\n",
      "Epoch 22/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6495 - accuracy: 0.6477 - val_loss: 0.6480 - val_accuracy: 0.6504\n",
      "Epoch 23/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6489 - accuracy: 0.6477 - val_loss: 0.6474 - val_accuracy: 0.6504\n",
      "Epoch 24/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6484 - accuracy: 0.6477 - val_loss: 0.6468 - val_accuracy: 0.6504\n",
      "Epoch 25/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6479 - accuracy: 0.6477 - val_loss: 0.6463 - val_accuracy: 0.6504\n",
      "Epoch 26/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6474 - accuracy: 0.6477 - val_loss: 0.6459 - val_accuracy: 0.6504\n",
      "Epoch 27/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6469 - accuracy: 0.6477 - val_loss: 0.6455 - val_accuracy: 0.6504\n",
      "Epoch 28/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6466 - accuracy: 0.6477 - val_loss: 0.6451 - val_accuracy: 0.6504\n",
      "Epoch 29/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6462 - accuracy: 0.6477 - val_loss: 0.6447 - val_accuracy: 0.6504\n",
      "Epoch 30/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6459 - accuracy: 0.6477 - val_loss: 0.6443 - val_accuracy: 0.6504\n",
      "Epoch 31/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6454 - accuracy: 0.6477 - val_loss: 0.6440 - val_accuracy: 0.6504\n",
      "Epoch 32/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6451 - accuracy: 0.6477 - val_loss: 0.6437 - val_accuracy: 0.6504\n",
      "Epoch 33/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6448 - accuracy: 0.6477 - val_loss: 0.6434 - val_accuracy: 0.6504\n",
      "Epoch 34/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6445 - accuracy: 0.6477 - val_loss: 0.6431 - val_accuracy: 0.6504\n",
      "Epoch 35/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6441 - accuracy: 0.6477 - val_loss: 0.6428 - val_accuracy: 0.6504\n",
      "Epoch 36/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6438 - accuracy: 0.6477 - val_loss: 0.6425 - val_accuracy: 0.6504\n",
      "Epoch 37/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6435 - accuracy: 0.6477 - val_loss: 0.6422 - val_accuracy: 0.6504\n",
      "Epoch 38/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6433 - accuracy: 0.6477 - val_loss: 0.6419 - val_accuracy: 0.6504\n",
      "Epoch 39/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6429 - accuracy: 0.6477 - val_loss: 0.6417 - val_accuracy: 0.6504\n",
      "Epoch 40/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6426 - accuracy: 0.6477 - val_loss: 0.6414 - val_accuracy: 0.6504\n",
      "Epoch 41/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6424 - accuracy: 0.6477 - val_loss: 0.6411 - val_accuracy: 0.6504\n",
      "Epoch 42/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6421 - accuracy: 0.6477 - val_loss: 0.6408 - val_accuracy: 0.6504\n",
      "Epoch 43/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6418 - accuracy: 0.6477 - val_loss: 0.6405 - val_accuracy: 0.6504\n",
      "Epoch 44/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6415 - accuracy: 0.6477 - val_loss: 0.6403 - val_accuracy: 0.6504\n",
      "Epoch 45/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6412 - accuracy: 0.6477 - val_loss: 0.6400 - val_accuracy: 0.6504\n",
      "Epoch 46/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6409 - accuracy: 0.6477 - val_loss: 0.6397 - val_accuracy: 0.6504\n",
      "Epoch 47/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6407 - accuracy: 0.6477 - val_loss: 0.6395 - val_accuracy: 0.6504\n",
      "Epoch 48/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6405 - accuracy: 0.6477 - val_loss: 0.6392 - val_accuracy: 0.6504\n",
      "Epoch 49/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6401 - accuracy: 0.6477 - val_loss: 0.6389 - val_accuracy: 0.6504\n",
      "Epoch 50/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6398 - accuracy: 0.6477 - val_loss: 0.6387 - val_accuracy: 0.6504\n",
      "Epoch 51/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6396 - accuracy: 0.6477 - val_loss: 0.6384 - val_accuracy: 0.6504\n",
      "Epoch 52/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6393 - accuracy: 0.6477 - val_loss: 0.6382 - val_accuracy: 0.6504\n",
      "Epoch 53/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6390 - accuracy: 0.6477 - val_loss: 0.6379 - val_accuracy: 0.6504\n",
      "Epoch 54/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6388 - accuracy: 0.6477 - val_loss: 0.6376 - val_accuracy: 0.6504\n",
      "Epoch 55/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6385 - accuracy: 0.6477 - val_loss: 0.6374 - val_accuracy: 0.6504\n",
      "Epoch 56/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6382 - accuracy: 0.6477 - val_loss: 0.6371 - val_accuracy: 0.6504\n",
      "Epoch 57/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6379 - accuracy: 0.6477 - val_loss: 0.6369 - val_accuracy: 0.6504\n",
      "Epoch 58/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6377 - accuracy: 0.6477 - val_loss: 0.6366 - val_accuracy: 0.6504\n",
      "Epoch 59/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6374 - accuracy: 0.6477 - val_loss: 0.6363 - val_accuracy: 0.6504\n",
      "Epoch 60/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6370 - accuracy: 0.6477 - val_loss: 0.6360 - val_accuracy: 0.6504\n",
      "Epoch 61/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6368 - accuracy: 0.6477 - val_loss: 0.6358 - val_accuracy: 0.6504\n",
      "Epoch 62/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6365 - accuracy: 0.6477 - val_loss: 0.6355 - val_accuracy: 0.6504\n",
      "Epoch 63/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6362 - accuracy: 0.6477 - val_loss: 0.6352 - val_accuracy: 0.6504\n",
      "Epoch 64/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6359 - accuracy: 0.6477 - val_loss: 0.6350 - val_accuracy: 0.6504\n",
      "Epoch 65/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6356 - accuracy: 0.6477 - val_loss: 0.6347 - val_accuracy: 0.6504\n",
      "Epoch 66/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6354 - accuracy: 0.6477 - val_loss: 0.6344 - val_accuracy: 0.6504\n",
      "Epoch 67/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6350 - accuracy: 0.6477 - val_loss: 0.6342 - val_accuracy: 0.6504\n",
      "Epoch 68/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6347 - accuracy: 0.6477 - val_loss: 0.6339 - val_accuracy: 0.6504\n",
      "Epoch 69/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6344 - accuracy: 0.6477 - val_loss: 0.6336 - val_accuracy: 0.6504\n",
      "Epoch 70/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6342 - accuracy: 0.6477 - val_loss: 0.6333 - val_accuracy: 0.6504\n",
      "Epoch 71/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6338 - accuracy: 0.6477 - val_loss: 0.6331 - val_accuracy: 0.6504\n",
      "Epoch 72/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6335 - accuracy: 0.6477 - val_loss: 0.6328 - val_accuracy: 0.6504\n",
      "Epoch 73/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6332 - accuracy: 0.6477 - val_loss: 0.6325 - val_accuracy: 0.6504\n",
      "Epoch 74/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6329 - accuracy: 0.6477 - val_loss: 0.6322 - val_accuracy: 0.6504\n",
      "Epoch 75/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6325 - accuracy: 0.6477 - val_loss: 0.6319 - val_accuracy: 0.6504\n",
      "Epoch 76/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6323 - accuracy: 0.6477 - val_loss: 0.6316 - val_accuracy: 0.6504\n",
      "Epoch 77/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6319 - accuracy: 0.6477 - val_loss: 0.6313 - val_accuracy: 0.6504\n",
      "Epoch 78/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6316 - accuracy: 0.6477 - val_loss: 0.6310 - val_accuracy: 0.6504\n",
      "Epoch 79/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6313 - accuracy: 0.6477 - val_loss: 0.6307 - val_accuracy: 0.6504\n",
      "Epoch 80/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6309 - accuracy: 0.6477 - val_loss: 0.6304 - val_accuracy: 0.6504\n",
      "Epoch 81/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6307 - accuracy: 0.6477 - val_loss: 0.6302 - val_accuracy: 0.6504\n",
      "Epoch 82/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6305 - accuracy: 0.6477 - val_loss: 0.6299 - val_accuracy: 0.6504\n",
      "Epoch 83/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6301 - accuracy: 0.6477 - val_loss: 0.6296 - val_accuracy: 0.6504\n",
      "Epoch 84/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6297 - accuracy: 0.6477 - val_loss: 0.6293 - val_accuracy: 0.6504\n",
      "Epoch 85/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6294 - accuracy: 0.6477 - val_loss: 0.6290 - val_accuracy: 0.6504\n",
      "Epoch 86/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6291 - accuracy: 0.6477 - val_loss: 0.6287 - val_accuracy: 0.6504\n",
      "Epoch 87/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6288 - accuracy: 0.6477 - val_loss: 0.6284 - val_accuracy: 0.6504\n",
      "Epoch 88/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6284 - accuracy: 0.6477 - val_loss: 0.6281 - val_accuracy: 0.6504\n",
      "Epoch 89/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6281 - accuracy: 0.6477 - val_loss: 0.6278 - val_accuracy: 0.6504\n",
      "Epoch 90/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6278 - accuracy: 0.6477 - val_loss: 0.6275 - val_accuracy: 0.6504\n",
      "Epoch 91/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6274 - accuracy: 0.6477 - val_loss: 0.6273 - val_accuracy: 0.6504\n",
      "Epoch 92/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6272 - accuracy: 0.6477 - val_loss: 0.6270 - val_accuracy: 0.6504\n",
      "Epoch 93/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6268 - accuracy: 0.6477 - val_loss: 0.6267 - val_accuracy: 0.6504\n",
      "Epoch 94/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6266 - accuracy: 0.6477 - val_loss: 0.6264 - val_accuracy: 0.6504\n",
      "Epoch 95/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6262 - accuracy: 0.6477 - val_loss: 0.6261 - val_accuracy: 0.6504\n",
      "Epoch 96/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6258 - accuracy: 0.6477 - val_loss: 0.6258 - val_accuracy: 0.6504\n",
      "Epoch 97/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6255 - accuracy: 0.6477 - val_loss: 0.6255 - val_accuracy: 0.6504\n",
      "Epoch 98/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6252 - accuracy: 0.6477 - val_loss: 0.6252 - val_accuracy: 0.6504\n",
      "Epoch 99/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6249 - accuracy: 0.6477 - val_loss: 0.6250 - val_accuracy: 0.6504\n",
      "Epoch 100/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6245 - accuracy: 0.6477 - val_loss: 0.6247 - val_accuracy: 0.6504\n",
      "Epoch 101/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6243 - accuracy: 0.6477 - val_loss: 0.6244 - val_accuracy: 0.6504\n",
      "Epoch 102/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6239 - accuracy: 0.6497 - val_loss: 0.6241 - val_accuracy: 0.6504\n",
      "Epoch 103/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6236 - accuracy: 0.6497 - val_loss: 0.6238 - val_accuracy: 0.6504\n",
      "Epoch 104/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6232 - accuracy: 0.6497 - val_loss: 0.6235 - val_accuracy: 0.6504\n",
      "Epoch 105/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6229 - accuracy: 0.6497 - val_loss: 0.6232 - val_accuracy: 0.6504\n",
      "Epoch 106/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6225 - accuracy: 0.6497 - val_loss: 0.6229 - val_accuracy: 0.6504\n",
      "Epoch 107/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6222 - accuracy: 0.6497 - val_loss: 0.6226 - val_accuracy: 0.6504\n",
      "Epoch 108/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6219 - accuracy: 0.6497 - val_loss: 0.6222 - val_accuracy: 0.6504\n",
      "Epoch 109/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6215 - accuracy: 0.6497 - val_loss: 0.6219 - val_accuracy: 0.6504\n",
      "Epoch 110/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6212 - accuracy: 0.6497 - val_loss: 0.6216 - val_accuracy: 0.6504\n",
      "Epoch 111/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6208 - accuracy: 0.6497 - val_loss: 0.6213 - val_accuracy: 0.6504\n",
      "Epoch 112/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6205 - accuracy: 0.6497 - val_loss: 0.6210 - val_accuracy: 0.6504\n",
      "Epoch 113/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6201 - accuracy: 0.6497 - val_loss: 0.6207 - val_accuracy: 0.6504\n",
      "Epoch 114/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6198 - accuracy: 0.6497 - val_loss: 0.6204 - val_accuracy: 0.6504\n",
      "Epoch 115/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6194 - accuracy: 0.6477 - val_loss: 0.6201 - val_accuracy: 0.6504\n",
      "Epoch 116/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6191 - accuracy: 0.6477 - val_loss: 0.6198 - val_accuracy: 0.6504\n",
      "Epoch 117/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6188 - accuracy: 0.6477 - val_loss: 0.6195 - val_accuracy: 0.6504\n",
      "Epoch 118/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6184 - accuracy: 0.6477 - val_loss: 0.6192 - val_accuracy: 0.6504\n",
      "Epoch 119/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6180 - accuracy: 0.6477 - val_loss: 0.6188 - val_accuracy: 0.6504\n",
      "Epoch 120/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6177 - accuracy: 0.6497 - val_loss: 0.6185 - val_accuracy: 0.6504\n",
      "Epoch 121/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6172 - accuracy: 0.6497 - val_loss: 0.6182 - val_accuracy: 0.6504\n",
      "Epoch 122/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6169 - accuracy: 0.6497 - val_loss: 0.6179 - val_accuracy: 0.6504\n",
      "Epoch 123/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6166 - accuracy: 0.6497 - val_loss: 0.6176 - val_accuracy: 0.6504\n",
      "Epoch 124/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6162 - accuracy: 0.6497 - val_loss: 0.6173 - val_accuracy: 0.6504\n",
      "Epoch 125/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6159 - accuracy: 0.6497 - val_loss: 0.6170 - val_accuracy: 0.6504\n",
      "Epoch 126/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6155 - accuracy: 0.6517 - val_loss: 0.6166 - val_accuracy: 0.6504\n",
      "Epoch 127/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6151 - accuracy: 0.6517 - val_loss: 0.6163 - val_accuracy: 0.6504\n",
      "Epoch 128/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6147 - accuracy: 0.6477 - val_loss: 0.6160 - val_accuracy: 0.6504\n",
      "Epoch 129/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6143 - accuracy: 0.6517 - val_loss: 0.6157 - val_accuracy: 0.6504\n",
      "Epoch 130/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6140 - accuracy: 0.6517 - val_loss: 0.6153 - val_accuracy: 0.6504\n",
      "Epoch 131/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6135 - accuracy: 0.6517 - val_loss: 0.6150 - val_accuracy: 0.6504\n",
      "Epoch 132/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6132 - accuracy: 0.6538 - val_loss: 0.6147 - val_accuracy: 0.6504\n",
      "Epoch 133/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6128 - accuracy: 0.6538 - val_loss: 0.6144 - val_accuracy: 0.6504\n",
      "Epoch 134/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6125 - accuracy: 0.6558 - val_loss: 0.6140 - val_accuracy: 0.6585\n",
      "Epoch 135/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6121 - accuracy: 0.6558 - val_loss: 0.6137 - val_accuracy: 0.6585\n",
      "Epoch 136/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6117 - accuracy: 0.6558 - val_loss: 0.6134 - val_accuracy: 0.6585\n",
      "Epoch 137/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6113 - accuracy: 0.6599 - val_loss: 0.6131 - val_accuracy: 0.6585\n",
      "Epoch 138/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6109 - accuracy: 0.6619 - val_loss: 0.6127 - val_accuracy: 0.6585\n",
      "Epoch 139/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6106 - accuracy: 0.6619 - val_loss: 0.6124 - val_accuracy: 0.6585\n",
      "Epoch 140/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6101 - accuracy: 0.6619 - val_loss: 0.6121 - val_accuracy: 0.6585\n",
      "Epoch 141/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6097 - accuracy: 0.6599 - val_loss: 0.6118 - val_accuracy: 0.6585\n",
      "Epoch 142/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6093 - accuracy: 0.6619 - val_loss: 0.6114 - val_accuracy: 0.6585\n",
      "Epoch 143/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6090 - accuracy: 0.6619 - val_loss: 0.6111 - val_accuracy: 0.6585\n",
      "Epoch 144/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6085 - accuracy: 0.6640 - val_loss: 0.6108 - val_accuracy: 0.6585\n",
      "Epoch 145/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6082 - accuracy: 0.6619 - val_loss: 0.6104 - val_accuracy: 0.6585\n",
      "Epoch 146/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6079 - accuracy: 0.6660 - val_loss: 0.6101 - val_accuracy: 0.6585\n",
      "Epoch 147/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6074 - accuracy: 0.6680 - val_loss: 0.6098 - val_accuracy: 0.6585\n",
      "Epoch 148/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6071 - accuracy: 0.6680 - val_loss: 0.6095 - val_accuracy: 0.6585\n",
      "Epoch 149/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6067 - accuracy: 0.6701 - val_loss: 0.6091 - val_accuracy: 0.6585\n",
      "Epoch 150/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6062 - accuracy: 0.6660 - val_loss: 0.6088 - val_accuracy: 0.6585\n",
      "Epoch 151/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6058 - accuracy: 0.6741 - val_loss: 0.6085 - val_accuracy: 0.6585\n",
      "Epoch 152/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6054 - accuracy: 0.6660 - val_loss: 0.6081 - val_accuracy: 0.6585\n",
      "Epoch 153/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6050 - accuracy: 0.6741 - val_loss: 0.6078 - val_accuracy: 0.6585\n",
      "Epoch 154/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6047 - accuracy: 0.6741 - val_loss: 0.6075 - val_accuracy: 0.6585\n",
      "Epoch 155/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6042 - accuracy: 0.6762 - val_loss: 0.6071 - val_accuracy: 0.6585\n",
      "Epoch 156/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6038 - accuracy: 0.6721 - val_loss: 0.6068 - val_accuracy: 0.6585\n",
      "Epoch 157/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6034 - accuracy: 0.6782 - val_loss: 0.6064 - val_accuracy: 0.6585\n",
      "Epoch 158/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6031 - accuracy: 0.6823 - val_loss: 0.6061 - val_accuracy: 0.6585\n",
      "Epoch 159/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6026 - accuracy: 0.6762 - val_loss: 0.6057 - val_accuracy: 0.6585\n",
      "Epoch 160/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6022 - accuracy: 0.6802 - val_loss: 0.6054 - val_accuracy: 0.6585\n",
      "Epoch 161/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6018 - accuracy: 0.6782 - val_loss: 0.6051 - val_accuracy: 0.6585\n",
      "Epoch 162/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6014 - accuracy: 0.6782 - val_loss: 0.6047 - val_accuracy: 0.6585\n",
      "Epoch 163/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6010 - accuracy: 0.6782 - val_loss: 0.6043 - val_accuracy: 0.6585\n",
      "Epoch 164/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6005 - accuracy: 0.6782 - val_loss: 0.6040 - val_accuracy: 0.6585\n",
      "Epoch 165/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6002 - accuracy: 0.6802 - val_loss: 0.6036 - val_accuracy: 0.6504\n",
      "Epoch 166/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5998 - accuracy: 0.6782 - val_loss: 0.6033 - val_accuracy: 0.6504\n",
      "Epoch 167/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5994 - accuracy: 0.6762 - val_loss: 0.6029 - val_accuracy: 0.6504\n",
      "Epoch 168/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5989 - accuracy: 0.6823 - val_loss: 0.6026 - val_accuracy: 0.6504\n",
      "Epoch 169/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5987 - accuracy: 0.6802 - val_loss: 0.6023 - val_accuracy: 0.6423\n",
      "Epoch 170/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5981 - accuracy: 0.6782 - val_loss: 0.6019 - val_accuracy: 0.6423\n",
      "Epoch 171/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5977 - accuracy: 0.6782 - val_loss: 0.6015 - val_accuracy: 0.6423\n",
      "Epoch 172/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5972 - accuracy: 0.6782 - val_loss: 0.6011 - val_accuracy: 0.6423\n",
      "Epoch 173/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5968 - accuracy: 0.6782 - val_loss: 0.6008 - val_accuracy: 0.6423\n",
      "Epoch 174/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5964 - accuracy: 0.6782 - val_loss: 0.6004 - val_accuracy: 0.6423\n",
      "Epoch 175/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5959 - accuracy: 0.6782 - val_loss: 0.6001 - val_accuracy: 0.6423\n",
      "Epoch 176/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5956 - accuracy: 0.6782 - val_loss: 0.5997 - val_accuracy: 0.6423\n",
      "Epoch 177/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5951 - accuracy: 0.6782 - val_loss: 0.5994 - val_accuracy: 0.6423\n",
      "Epoch 178/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5947 - accuracy: 0.6782 - val_loss: 0.5990 - val_accuracy: 0.6504\n",
      "Epoch 179/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5945 - accuracy: 0.6823 - val_loss: 0.5986 - val_accuracy: 0.6504\n",
      "Epoch 180/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5940 - accuracy: 0.6843 - val_loss: 0.5983 - val_accuracy: 0.6585\n",
      "Epoch 181/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5935 - accuracy: 0.6864 - val_loss: 0.5979 - val_accuracy: 0.6585\n",
      "Epoch 182/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5931 - accuracy: 0.6904 - val_loss: 0.5975 - val_accuracy: 0.6667\n",
      "Epoch 183/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5925 - accuracy: 0.6864 - val_loss: 0.5972 - val_accuracy: 0.6748\n",
      "Epoch 184/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5922 - accuracy: 0.6843 - val_loss: 0.5968 - val_accuracy: 0.6748\n",
      "Epoch 185/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5918 - accuracy: 0.6823 - val_loss: 0.5964 - val_accuracy: 0.6748\n",
      "Epoch 186/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5913 - accuracy: 0.6843 - val_loss: 0.5960 - val_accuracy: 0.6748\n",
      "Epoch 187/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5910 - accuracy: 0.6843 - val_loss: 0.5956 - val_accuracy: 0.6748\n",
      "Epoch 188/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5904 - accuracy: 0.6843 - val_loss: 0.5953 - val_accuracy: 0.6667\n",
      "Epoch 189/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5901 - accuracy: 0.6843 - val_loss: 0.5949 - val_accuracy: 0.6667\n",
      "Epoch 190/800\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5895 - accuracy: 0.6843 - val_loss: 0.5946 - val_accuracy: 0.6667\n",
      "Epoch 191/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5891 - accuracy: 0.6823 - val_loss: 0.5942 - val_accuracy: 0.6667\n",
      "Epoch 192/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5888 - accuracy: 0.6864 - val_loss: 0.5938 - val_accuracy: 0.6667\n",
      "Epoch 193/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5883 - accuracy: 0.6843 - val_loss: 0.5934 - val_accuracy: 0.6667\n",
      "Epoch 194/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5879 - accuracy: 0.6864 - val_loss: 0.5930 - val_accuracy: 0.6667\n",
      "Epoch 195/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5876 - accuracy: 0.6864 - val_loss: 0.5927 - val_accuracy: 0.6667\n",
      "Epoch 196/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5870 - accuracy: 0.6843 - val_loss: 0.5923 - val_accuracy: 0.6667\n",
      "Epoch 197/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5867 - accuracy: 0.6904 - val_loss: 0.5919 - val_accuracy: 0.6667\n",
      "Epoch 198/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5861 - accuracy: 0.6884 - val_loss: 0.5915 - val_accuracy: 0.6748\n",
      "Epoch 199/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5858 - accuracy: 0.6864 - val_loss: 0.5911 - val_accuracy: 0.6748\n",
      "Epoch 200/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5854 - accuracy: 0.6884 - val_loss: 0.5908 - val_accuracy: 0.6748\n",
      "Epoch 201/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5848 - accuracy: 0.6864 - val_loss: 0.5904 - val_accuracy: 0.6748\n",
      "Epoch 202/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5844 - accuracy: 0.6864 - val_loss: 0.5900 - val_accuracy: 0.6829\n",
      "Epoch 203/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5840 - accuracy: 0.6884 - val_loss: 0.5896 - val_accuracy: 0.6748\n",
      "Epoch 204/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5836 - accuracy: 0.6904 - val_loss: 0.5893 - val_accuracy: 0.6748\n",
      "Epoch 205/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5831 - accuracy: 0.6884 - val_loss: 0.5889 - val_accuracy: 0.6748\n",
      "Epoch 206/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5827 - accuracy: 0.6884 - val_loss: 0.5885 - val_accuracy: 0.6748\n",
      "Epoch 207/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5822 - accuracy: 0.6925 - val_loss: 0.5881 - val_accuracy: 0.6748\n",
      "Epoch 208/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5818 - accuracy: 0.6904 - val_loss: 0.5877 - val_accuracy: 0.6748\n",
      "Epoch 209/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5817 - accuracy: 0.6945 - val_loss: 0.5873 - val_accuracy: 0.6829\n",
      "Epoch 210/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5808 - accuracy: 0.6925 - val_loss: 0.5870 - val_accuracy: 0.6748\n",
      "Epoch 211/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5807 - accuracy: 0.6925 - val_loss: 0.5866 - val_accuracy: 0.6748\n",
      "Epoch 212/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5800 - accuracy: 0.6945 - val_loss: 0.5862 - val_accuracy: 0.6748\n",
      "Epoch 213/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5797 - accuracy: 0.6904 - val_loss: 0.5858 - val_accuracy: 0.6748\n",
      "Epoch 214/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5792 - accuracy: 0.6945 - val_loss: 0.5855 - val_accuracy: 0.6911\n",
      "Epoch 215/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5787 - accuracy: 0.6925 - val_loss: 0.5851 - val_accuracy: 0.6911\n",
      "Epoch 216/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5782 - accuracy: 0.6925 - val_loss: 0.5847 - val_accuracy: 0.6911\n",
      "Epoch 217/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5778 - accuracy: 0.6904 - val_loss: 0.5842 - val_accuracy: 0.6911\n",
      "Epoch 218/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5775 - accuracy: 0.6904 - val_loss: 0.5839 - val_accuracy: 0.6992\n",
      "Epoch 219/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5771 - accuracy: 0.6904 - val_loss: 0.5834 - val_accuracy: 0.6911\n",
      "Epoch 220/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5765 - accuracy: 0.6925 - val_loss: 0.5831 - val_accuracy: 0.6992\n",
      "Epoch 221/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5762 - accuracy: 0.6925 - val_loss: 0.5827 - val_accuracy: 0.6992\n",
      "Epoch 222/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5757 - accuracy: 0.6925 - val_loss: 0.5823 - val_accuracy: 0.6911\n",
      "Epoch 223/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5751 - accuracy: 0.6965 - val_loss: 0.5819 - val_accuracy: 0.6911\n",
      "Epoch 224/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5747 - accuracy: 0.6925 - val_loss: 0.5815 - val_accuracy: 0.6911\n",
      "Epoch 225/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5742 - accuracy: 0.6925 - val_loss: 0.5811 - val_accuracy: 0.6911\n",
      "Epoch 226/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5738 - accuracy: 0.6945 - val_loss: 0.5807 - val_accuracy: 0.6911\n",
      "Epoch 227/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5733 - accuracy: 0.6925 - val_loss: 0.5803 - val_accuracy: 0.6911\n",
      "Epoch 228/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5730 - accuracy: 0.6925 - val_loss: 0.5799 - val_accuracy: 0.6911\n",
      "Epoch 229/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5726 - accuracy: 0.6925 - val_loss: 0.5795 - val_accuracy: 0.6911\n",
      "Epoch 230/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5723 - accuracy: 0.6925 - val_loss: 0.5792 - val_accuracy: 0.6911\n",
      "Epoch 231/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5717 - accuracy: 0.6965 - val_loss: 0.5787 - val_accuracy: 0.6911\n",
      "Epoch 232/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5712 - accuracy: 0.6945 - val_loss: 0.5783 - val_accuracy: 0.6911\n",
      "Epoch 233/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5707 - accuracy: 0.6925 - val_loss: 0.5780 - val_accuracy: 0.6911\n",
      "Epoch 234/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5704 - accuracy: 0.6925 - val_loss: 0.5776 - val_accuracy: 0.6911\n",
      "Epoch 235/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5701 - accuracy: 0.6965 - val_loss: 0.5772 - val_accuracy: 0.6911\n",
      "Epoch 236/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5694 - accuracy: 0.6965 - val_loss: 0.5768 - val_accuracy: 0.6911\n",
      "Epoch 237/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5692 - accuracy: 0.6904 - val_loss: 0.5764 - val_accuracy: 0.6992\n",
      "Epoch 238/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5687 - accuracy: 0.6945 - val_loss: 0.5760 - val_accuracy: 0.6911\n",
      "Epoch 239/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5681 - accuracy: 0.6925 - val_loss: 0.5757 - val_accuracy: 0.6829\n",
      "Epoch 240/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5677 - accuracy: 0.6925 - val_loss: 0.5752 - val_accuracy: 0.6829\n",
      "Epoch 241/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5673 - accuracy: 0.6945 - val_loss: 0.5749 - val_accuracy: 0.6829\n",
      "Epoch 242/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5668 - accuracy: 0.6965 - val_loss: 0.5745 - val_accuracy: 0.6829\n",
      "Epoch 243/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5664 - accuracy: 0.6945 - val_loss: 0.5741 - val_accuracy: 0.6829\n",
      "Epoch 244/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5659 - accuracy: 0.6965 - val_loss: 0.5737 - val_accuracy: 0.6829\n",
      "Epoch 245/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5655 - accuracy: 0.6965 - val_loss: 0.5733 - val_accuracy: 0.6829\n",
      "Epoch 246/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5652 - accuracy: 0.6965 - val_loss: 0.5729 - val_accuracy: 0.6829\n",
      "Epoch 247/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5650 - accuracy: 0.6945 - val_loss: 0.5726 - val_accuracy: 0.6829\n",
      "Epoch 248/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5642 - accuracy: 0.6945 - val_loss: 0.5722 - val_accuracy: 0.6829\n",
      "Epoch 249/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5639 - accuracy: 0.6986 - val_loss: 0.5718 - val_accuracy: 0.6829\n",
      "Epoch 250/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5633 - accuracy: 0.7026 - val_loss: 0.5714 - val_accuracy: 0.6829\n",
      "Epoch 251/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5627 - accuracy: 0.6986 - val_loss: 0.5710 - val_accuracy: 0.6829\n",
      "Epoch 252/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5625 - accuracy: 0.6986 - val_loss: 0.5706 - val_accuracy: 0.6829\n",
      "Epoch 253/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5620 - accuracy: 0.6986 - val_loss: 0.5703 - val_accuracy: 0.6829\n",
      "Epoch 254/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5616 - accuracy: 0.6986 - val_loss: 0.5699 - val_accuracy: 0.6829\n",
      "Epoch 255/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5612 - accuracy: 0.6965 - val_loss: 0.5695 - val_accuracy: 0.6911\n",
      "Epoch 256/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5606 - accuracy: 0.7006 - val_loss: 0.5692 - val_accuracy: 0.6992\n",
      "Epoch 257/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5601 - accuracy: 0.6965 - val_loss: 0.5688 - val_accuracy: 0.6992\n",
      "Epoch 258/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5599 - accuracy: 0.6965 - val_loss: 0.5683 - val_accuracy: 0.6992\n",
      "Epoch 259/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5593 - accuracy: 0.6965 - val_loss: 0.5679 - val_accuracy: 0.6992\n",
      "Epoch 260/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5590 - accuracy: 0.6986 - val_loss: 0.5676 - val_accuracy: 0.6992\n",
      "Epoch 261/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5583 - accuracy: 0.6965 - val_loss: 0.5672 - val_accuracy: 0.6992\n",
      "Epoch 262/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5580 - accuracy: 0.6986 - val_loss: 0.5668 - val_accuracy: 0.6992\n",
      "Epoch 263/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5574 - accuracy: 0.6986 - val_loss: 0.5664 - val_accuracy: 0.6992\n",
      "Epoch 264/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5571 - accuracy: 0.6945 - val_loss: 0.5660 - val_accuracy: 0.6992\n",
      "Epoch 265/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5567 - accuracy: 0.7026 - val_loss: 0.5657 - val_accuracy: 0.6992\n",
      "Epoch 266/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5562 - accuracy: 0.6965 - val_loss: 0.5653 - val_accuracy: 0.6992\n",
      "Epoch 267/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5557 - accuracy: 0.6965 - val_loss: 0.5649 - val_accuracy: 0.6992\n",
      "Epoch 268/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5552 - accuracy: 0.6965 - val_loss: 0.5645 - val_accuracy: 0.6992\n",
      "Epoch 269/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5548 - accuracy: 0.6965 - val_loss: 0.5641 - val_accuracy: 0.6992\n",
      "Epoch 270/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5545 - accuracy: 0.6965 - val_loss: 0.5638 - val_accuracy: 0.6992\n",
      "Epoch 271/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5538 - accuracy: 0.6945 - val_loss: 0.5634 - val_accuracy: 0.6992\n",
      "Epoch 272/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5538 - accuracy: 0.6945 - val_loss: 0.5631 - val_accuracy: 0.6992\n",
      "Epoch 273/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5532 - accuracy: 0.6965 - val_loss: 0.5627 - val_accuracy: 0.6992\n",
      "Epoch 274/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5526 - accuracy: 0.6925 - val_loss: 0.5623 - val_accuracy: 0.6992\n",
      "Epoch 275/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5523 - accuracy: 0.6965 - val_loss: 0.5620 - val_accuracy: 0.6911\n",
      "Epoch 276/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5517 - accuracy: 0.6945 - val_loss: 0.5616 - val_accuracy: 0.6911\n",
      "Epoch 277/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5512 - accuracy: 0.6925 - val_loss: 0.5613 - val_accuracy: 0.6911\n",
      "Epoch 278/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5513 - accuracy: 0.6965 - val_loss: 0.5609 - val_accuracy: 0.6992\n",
      "Epoch 279/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5504 - accuracy: 0.6925 - val_loss: 0.5605 - val_accuracy: 0.6992\n",
      "Epoch 280/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5499 - accuracy: 0.6945 - val_loss: 0.5601 - val_accuracy: 0.6911\n",
      "Epoch 281/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5495 - accuracy: 0.6945 - val_loss: 0.5597 - val_accuracy: 0.6992\n",
      "Epoch 282/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5493 - accuracy: 0.6925 - val_loss: 0.5594 - val_accuracy: 0.6911\n",
      "Epoch 283/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5486 - accuracy: 0.6965 - val_loss: 0.5591 - val_accuracy: 0.6911\n",
      "Epoch 284/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5482 - accuracy: 0.6945 - val_loss: 0.5588 - val_accuracy: 0.6911\n",
      "Epoch 285/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5476 - accuracy: 0.6965 - val_loss: 0.5584 - val_accuracy: 0.6911\n",
      "Epoch 286/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5473 - accuracy: 0.6986 - val_loss: 0.5580 - val_accuracy: 0.6911\n",
      "Epoch 287/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5471 - accuracy: 0.6945 - val_loss: 0.5577 - val_accuracy: 0.6911\n",
      "Epoch 288/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5465 - accuracy: 0.6986 - val_loss: 0.5573 - val_accuracy: 0.6911\n",
      "Epoch 289/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5459 - accuracy: 0.6986 - val_loss: 0.5569 - val_accuracy: 0.6911\n",
      "Epoch 290/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5456 - accuracy: 0.7006 - val_loss: 0.5565 - val_accuracy: 0.6911\n",
      "Epoch 291/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5451 - accuracy: 0.6986 - val_loss: 0.5562 - val_accuracy: 0.6911\n",
      "Epoch 292/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5448 - accuracy: 0.6986 - val_loss: 0.5558 - val_accuracy: 0.6911\n",
      "Epoch 293/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5442 - accuracy: 0.7006 - val_loss: 0.5555 - val_accuracy: 0.6911\n",
      "Epoch 294/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5438 - accuracy: 0.6986 - val_loss: 0.5551 - val_accuracy: 0.6911\n",
      "Epoch 295/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5433 - accuracy: 0.6986 - val_loss: 0.5548 - val_accuracy: 0.6829\n",
      "Epoch 296/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5429 - accuracy: 0.6986 - val_loss: 0.5545 - val_accuracy: 0.6911\n",
      "Epoch 297/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5425 - accuracy: 0.6986 - val_loss: 0.5541 - val_accuracy: 0.6829\n",
      "Epoch 298/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5419 - accuracy: 0.7006 - val_loss: 0.5537 - val_accuracy: 0.6911\n",
      "Epoch 299/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5417 - accuracy: 0.7006 - val_loss: 0.5533 - val_accuracy: 0.6911\n",
      "Epoch 300/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5412 - accuracy: 0.7006 - val_loss: 0.5530 - val_accuracy: 0.6911\n",
      "Epoch 301/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5408 - accuracy: 0.7026 - val_loss: 0.5526 - val_accuracy: 0.6911\n",
      "Epoch 302/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5402 - accuracy: 0.7006 - val_loss: 0.5523 - val_accuracy: 0.6829\n",
      "Epoch 303/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5399 - accuracy: 0.7047 - val_loss: 0.5520 - val_accuracy: 0.6829\n",
      "Epoch 304/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5394 - accuracy: 0.7026 - val_loss: 0.5516 - val_accuracy: 0.6829\n",
      "Epoch 305/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5389 - accuracy: 0.7026 - val_loss: 0.5513 - val_accuracy: 0.6829\n",
      "Epoch 306/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5384 - accuracy: 0.7047 - val_loss: 0.5510 - val_accuracy: 0.6829\n",
      "Epoch 307/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5382 - accuracy: 0.7006 - val_loss: 0.5507 - val_accuracy: 0.6829\n",
      "Epoch 308/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5377 - accuracy: 0.7067 - val_loss: 0.5504 - val_accuracy: 0.6829\n",
      "Epoch 309/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5376 - accuracy: 0.7047 - val_loss: 0.5501 - val_accuracy: 0.6911\n",
      "Epoch 310/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5366 - accuracy: 0.7047 - val_loss: 0.5498 - val_accuracy: 0.6829\n",
      "Epoch 311/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5363 - accuracy: 0.7088 - val_loss: 0.5494 - val_accuracy: 0.6911\n",
      "Epoch 312/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5358 - accuracy: 0.7047 - val_loss: 0.5490 - val_accuracy: 0.6911\n",
      "Epoch 313/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5354 - accuracy: 0.7088 - val_loss: 0.5487 - val_accuracy: 0.6911\n",
      "Epoch 314/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5351 - accuracy: 0.7088 - val_loss: 0.5484 - val_accuracy: 0.6829\n",
      "Epoch 315/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5347 - accuracy: 0.7088 - val_loss: 0.5481 - val_accuracy: 0.6829\n",
      "Epoch 316/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5344 - accuracy: 0.7128 - val_loss: 0.5477 - val_accuracy: 0.6911\n",
      "Epoch 317/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5338 - accuracy: 0.7108 - val_loss: 0.5474 - val_accuracy: 0.6829\n",
      "Epoch 318/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5336 - accuracy: 0.7088 - val_loss: 0.5471 - val_accuracy: 0.6829\n",
      "Epoch 319/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5331 - accuracy: 0.7128 - val_loss: 0.5468 - val_accuracy: 0.6829\n",
      "Epoch 320/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5327 - accuracy: 0.7108 - val_loss: 0.5465 - val_accuracy: 0.6829\n",
      "Epoch 321/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5322 - accuracy: 0.7088 - val_loss: 0.5462 - val_accuracy: 0.6829\n",
      "Epoch 322/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5316 - accuracy: 0.7128 - val_loss: 0.5459 - val_accuracy: 0.6829\n",
      "Epoch 323/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5314 - accuracy: 0.7128 - val_loss: 0.5456 - val_accuracy: 0.6829\n",
      "Epoch 324/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5308 - accuracy: 0.7128 - val_loss: 0.5452 - val_accuracy: 0.6829\n",
      "Epoch 325/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5304 - accuracy: 0.7149 - val_loss: 0.5449 - val_accuracy: 0.6829\n",
      "Epoch 326/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5300 - accuracy: 0.7149 - val_loss: 0.5446 - val_accuracy: 0.6829\n",
      "Epoch 327/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5301 - accuracy: 0.7149 - val_loss: 0.5442 - val_accuracy: 0.6829\n",
      "Epoch 328/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5293 - accuracy: 0.7149 - val_loss: 0.5439 - val_accuracy: 0.6829\n",
      "Epoch 329/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5288 - accuracy: 0.7128 - val_loss: 0.5437 - val_accuracy: 0.6829\n",
      "Epoch 330/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5282 - accuracy: 0.7210 - val_loss: 0.5434 - val_accuracy: 0.6829\n",
      "Epoch 331/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5278 - accuracy: 0.7149 - val_loss: 0.5431 - val_accuracy: 0.6829\n",
      "Epoch 332/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5275 - accuracy: 0.7189 - val_loss: 0.5428 - val_accuracy: 0.6829\n",
      "Epoch 333/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5272 - accuracy: 0.7149 - val_loss: 0.5426 - val_accuracy: 0.6829\n",
      "Epoch 334/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5266 - accuracy: 0.7169 - val_loss: 0.5422 - val_accuracy: 0.6829\n",
      "Epoch 335/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5264 - accuracy: 0.7128 - val_loss: 0.5419 - val_accuracy: 0.6829\n",
      "Epoch 336/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5259 - accuracy: 0.7149 - val_loss: 0.5418 - val_accuracy: 0.6911\n",
      "Epoch 337/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5255 - accuracy: 0.7230 - val_loss: 0.5414 - val_accuracy: 0.6911\n",
      "Epoch 338/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5249 - accuracy: 0.7169 - val_loss: 0.5411 - val_accuracy: 0.6829\n",
      "Epoch 339/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5247 - accuracy: 0.7149 - val_loss: 0.5408 - val_accuracy: 0.6911\n",
      "Epoch 340/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5242 - accuracy: 0.7149 - val_loss: 0.5406 - val_accuracy: 0.6992\n",
      "Epoch 341/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5239 - accuracy: 0.7189 - val_loss: 0.5403 - val_accuracy: 0.6992\n",
      "Epoch 342/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5234 - accuracy: 0.7169 - val_loss: 0.5400 - val_accuracy: 0.6992\n",
      "Epoch 343/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5230 - accuracy: 0.7169 - val_loss: 0.5398 - val_accuracy: 0.6992\n",
      "Epoch 344/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5229 - accuracy: 0.7169 - val_loss: 0.5395 - val_accuracy: 0.6992\n",
      "Epoch 345/800\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5223 - accuracy: 0.7189 - val_loss: 0.5392 - val_accuracy: 0.6992\n",
      "Epoch 346/800\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5221 - accuracy: 0.7169 - val_loss: 0.5389 - val_accuracy: 0.6992\n",
      "Epoch 347/800\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.5214 - accuracy: 0.7251 - val_loss: 0.5386 - val_accuracy: 0.6992\n",
      "Epoch 348/800\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5213 - accuracy: 0.7149 - val_loss: 0.5384 - val_accuracy: 0.6992\n",
      "Epoch 349/800\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.5205 - accuracy: 0.7230 - val_loss: 0.5380 - val_accuracy: 0.6992\n",
      "Epoch 350/800\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5201 - accuracy: 0.7149 - val_loss: 0.5380 - val_accuracy: 0.6992\n",
      "Epoch 351/800\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5197 - accuracy: 0.7251 - val_loss: 0.5375 - val_accuracy: 0.6992\n",
      "Epoch 352/800\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5193 - accuracy: 0.7169 - val_loss: 0.5373 - val_accuracy: 0.6992\n",
      "Epoch 353/800\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.5189 - accuracy: 0.7169 - val_loss: 0.5370 - val_accuracy: 0.6992\n",
      "Epoch 354/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5187 - accuracy: 0.7169 - val_loss: 0.5369 - val_accuracy: 0.6992\n",
      "Epoch 355/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5186 - accuracy: 0.7271 - val_loss: 0.5365 - val_accuracy: 0.6992\n",
      "Epoch 356/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5177 - accuracy: 0.7251 - val_loss: 0.5362 - val_accuracy: 0.6992\n",
      "Epoch 357/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5175 - accuracy: 0.7169 - val_loss: 0.5361 - val_accuracy: 0.6992\n",
      "Epoch 358/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5172 - accuracy: 0.7271 - val_loss: 0.5357 - val_accuracy: 0.6992\n",
      "Epoch 359/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5166 - accuracy: 0.7230 - val_loss: 0.5354 - val_accuracy: 0.6992\n",
      "Epoch 360/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5166 - accuracy: 0.7210 - val_loss: 0.5353 - val_accuracy: 0.7073\n",
      "Epoch 361/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5158 - accuracy: 0.7230 - val_loss: 0.5350 - val_accuracy: 0.7073\n",
      "Epoch 362/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5157 - accuracy: 0.7271 - val_loss: 0.5347 - val_accuracy: 0.6992\n",
      "Epoch 363/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5158 - accuracy: 0.7291 - val_loss: 0.5345 - val_accuracy: 0.6992\n",
      "Epoch 364/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5147 - accuracy: 0.7312 - val_loss: 0.5342 - val_accuracy: 0.7073\n",
      "Epoch 365/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5144 - accuracy: 0.7169 - val_loss: 0.5341 - val_accuracy: 0.7073\n",
      "Epoch 366/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5141 - accuracy: 0.7291 - val_loss: 0.5339 - val_accuracy: 0.7073\n",
      "Epoch 367/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5135 - accuracy: 0.7291 - val_loss: 0.5338 - val_accuracy: 0.7073\n",
      "Epoch 368/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5134 - accuracy: 0.7332 - val_loss: 0.5334 - val_accuracy: 0.6992\n",
      "Epoch 369/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5131 - accuracy: 0.7271 - val_loss: 0.5333 - val_accuracy: 0.6992\n",
      "Epoch 370/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5125 - accuracy: 0.7291 - val_loss: 0.5331 - val_accuracy: 0.6992\n",
      "Epoch 371/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5123 - accuracy: 0.7312 - val_loss: 0.5329 - val_accuracy: 0.6992\n",
      "Epoch 372/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5117 - accuracy: 0.7291 - val_loss: 0.5326 - val_accuracy: 0.6992\n",
      "Epoch 373/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5114 - accuracy: 0.7312 - val_loss: 0.5322 - val_accuracy: 0.7073\n",
      "Epoch 374/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5114 - accuracy: 0.7271 - val_loss: 0.5320 - val_accuracy: 0.7073\n",
      "Epoch 375/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5107 - accuracy: 0.7312 - val_loss: 0.5318 - val_accuracy: 0.7073\n",
      "Epoch 376/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5107 - accuracy: 0.7291 - val_loss: 0.5315 - val_accuracy: 0.7073\n",
      "Epoch 377/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5103 - accuracy: 0.7312 - val_loss: 0.5313 - val_accuracy: 0.7073\n",
      "Epoch 378/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5096 - accuracy: 0.7291 - val_loss: 0.5312 - val_accuracy: 0.7073\n",
      "Epoch 379/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5097 - accuracy: 0.7291 - val_loss: 0.5311 - val_accuracy: 0.6992\n",
      "Epoch 380/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5097 - accuracy: 0.7291 - val_loss: 0.5309 - val_accuracy: 0.6992\n",
      "Epoch 381/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5085 - accuracy: 0.7312 - val_loss: 0.5308 - val_accuracy: 0.6992\n",
      "Epoch 382/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5082 - accuracy: 0.7312 - val_loss: 0.5306 - val_accuracy: 0.6992\n",
      "Epoch 383/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5083 - accuracy: 0.7332 - val_loss: 0.5304 - val_accuracy: 0.6992\n",
      "Epoch 384/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5076 - accuracy: 0.7332 - val_loss: 0.5301 - val_accuracy: 0.7073\n",
      "Epoch 385/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5073 - accuracy: 0.7332 - val_loss: 0.5300 - val_accuracy: 0.7073\n",
      "Epoch 386/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5068 - accuracy: 0.7393 - val_loss: 0.5296 - val_accuracy: 0.7073\n",
      "Epoch 387/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5062 - accuracy: 0.7312 - val_loss: 0.5294 - val_accuracy: 0.7073\n",
      "Epoch 388/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5059 - accuracy: 0.7373 - val_loss: 0.5292 - val_accuracy: 0.7073\n",
      "Epoch 389/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5055 - accuracy: 0.7373 - val_loss: 0.5290 - val_accuracy: 0.7073\n",
      "Epoch 390/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5055 - accuracy: 0.7312 - val_loss: 0.5288 - val_accuracy: 0.7073\n",
      "Epoch 391/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5050 - accuracy: 0.7373 - val_loss: 0.5286 - val_accuracy: 0.7073\n",
      "Epoch 392/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5047 - accuracy: 0.7332 - val_loss: 0.5287 - val_accuracy: 0.7073\n",
      "Epoch 393/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5043 - accuracy: 0.7454 - val_loss: 0.5283 - val_accuracy: 0.7073\n",
      "Epoch 394/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5039 - accuracy: 0.7454 - val_loss: 0.5280 - val_accuracy: 0.7073\n",
      "Epoch 395/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5038 - accuracy: 0.7352 - val_loss: 0.5279 - val_accuracy: 0.7073\n",
      "Epoch 396/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5040 - accuracy: 0.7393 - val_loss: 0.5279 - val_accuracy: 0.7073\n",
      "Epoch 397/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5031 - accuracy: 0.7393 - val_loss: 0.5278 - val_accuracy: 0.7073\n",
      "Epoch 398/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5028 - accuracy: 0.7373 - val_loss: 0.5278 - val_accuracy: 0.7073\n",
      "Epoch 399/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5025 - accuracy: 0.7454 - val_loss: 0.5275 - val_accuracy: 0.7073\n",
      "Epoch 400/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5022 - accuracy: 0.7413 - val_loss: 0.5273 - val_accuracy: 0.7073\n",
      "Epoch 401/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5016 - accuracy: 0.7413 - val_loss: 0.5269 - val_accuracy: 0.7073\n",
      "Epoch 402/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5014 - accuracy: 0.7393 - val_loss: 0.5268 - val_accuracy: 0.7073\n",
      "Epoch 403/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5010 - accuracy: 0.7434 - val_loss: 0.5266 - val_accuracy: 0.7073\n",
      "Epoch 404/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5008 - accuracy: 0.7393 - val_loss: 0.5264 - val_accuracy: 0.7073\n",
      "Epoch 405/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5012 - accuracy: 0.7373 - val_loss: 0.5261 - val_accuracy: 0.7154\n",
      "Epoch 406/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5002 - accuracy: 0.7413 - val_loss: 0.5260 - val_accuracy: 0.7154\n",
      "Epoch 407/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5001 - accuracy: 0.7393 - val_loss: 0.5259 - val_accuracy: 0.7073\n",
      "Epoch 408/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4995 - accuracy: 0.7413 - val_loss: 0.5259 - val_accuracy: 0.7073\n",
      "Epoch 409/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4991 - accuracy: 0.7434 - val_loss: 0.5258 - val_accuracy: 0.7073\n",
      "Epoch 410/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4988 - accuracy: 0.7352 - val_loss: 0.5254 - val_accuracy: 0.7154\n",
      "Epoch 411/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4981 - accuracy: 0.7454 - val_loss: 0.5254 - val_accuracy: 0.7154\n",
      "Epoch 412/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4982 - accuracy: 0.7373 - val_loss: 0.5252 - val_accuracy: 0.7154\n",
      "Epoch 413/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4982 - accuracy: 0.7373 - val_loss: 0.5253 - val_accuracy: 0.7073\n",
      "Epoch 414/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4980 - accuracy: 0.7434 - val_loss: 0.5251 - val_accuracy: 0.7073\n",
      "Epoch 415/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4971 - accuracy: 0.7413 - val_loss: 0.5250 - val_accuracy: 0.7073\n",
      "Epoch 416/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4968 - accuracy: 0.7373 - val_loss: 0.5248 - val_accuracy: 0.7073\n",
      "Epoch 417/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4968 - accuracy: 0.7393 - val_loss: 0.5246 - val_accuracy: 0.7154\n",
      "Epoch 418/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4963 - accuracy: 0.7393 - val_loss: 0.5244 - val_accuracy: 0.7154\n",
      "Epoch 419/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4960 - accuracy: 0.7393 - val_loss: 0.5244 - val_accuracy: 0.7154\n",
      "Epoch 420/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4959 - accuracy: 0.7393 - val_loss: 0.5242 - val_accuracy: 0.7154\n",
      "Epoch 421/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4956 - accuracy: 0.7413 - val_loss: 0.5242 - val_accuracy: 0.7073\n",
      "Epoch 422/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4956 - accuracy: 0.7393 - val_loss: 0.5240 - val_accuracy: 0.7154\n",
      "Epoch 423/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4948 - accuracy: 0.7413 - val_loss: 0.5239 - val_accuracy: 0.7073\n",
      "Epoch 424/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4947 - accuracy: 0.7352 - val_loss: 0.5237 - val_accuracy: 0.7154\n",
      "Epoch 425/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4948 - accuracy: 0.7373 - val_loss: 0.5234 - val_accuracy: 0.7154\n",
      "Epoch 426/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4946 - accuracy: 0.7393 - val_loss: 0.5233 - val_accuracy: 0.7154\n",
      "Epoch 427/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4937 - accuracy: 0.7393 - val_loss: 0.5232 - val_accuracy: 0.7154\n",
      "Epoch 428/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4932 - accuracy: 0.7393 - val_loss: 0.5231 - val_accuracy: 0.7154\n",
      "Epoch 429/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4933 - accuracy: 0.7434 - val_loss: 0.5231 - val_accuracy: 0.7073\n",
      "Epoch 430/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4927 - accuracy: 0.7352 - val_loss: 0.5230 - val_accuracy: 0.7073\n",
      "Epoch 431/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4924 - accuracy: 0.7454 - val_loss: 0.5231 - val_accuracy: 0.7073\n",
      "Epoch 432/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4920 - accuracy: 0.7352 - val_loss: 0.5229 - val_accuracy: 0.6992\n",
      "Epoch 433/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4920 - accuracy: 0.7393 - val_loss: 0.5228 - val_accuracy: 0.6992\n",
      "Epoch 434/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4917 - accuracy: 0.7373 - val_loss: 0.5227 - val_accuracy: 0.6992\n",
      "Epoch 435/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4915 - accuracy: 0.7413 - val_loss: 0.5226 - val_accuracy: 0.6992\n",
      "Epoch 436/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4913 - accuracy: 0.7393 - val_loss: 0.5225 - val_accuracy: 0.6992\n",
      "Epoch 437/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4910 - accuracy: 0.7393 - val_loss: 0.5223 - val_accuracy: 0.7073\n",
      "Epoch 438/800\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4906 - accuracy: 0.7454 - val_loss: 0.5223 - val_accuracy: 0.6992\n",
      "Epoch 439/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4902 - accuracy: 0.7373 - val_loss: 0.5221 - val_accuracy: 0.7073\n",
      "Epoch 440/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4902 - accuracy: 0.7393 - val_loss: 0.5220 - val_accuracy: 0.7073\n",
      "Epoch 441/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4899 - accuracy: 0.7454 - val_loss: 0.5222 - val_accuracy: 0.7154\n",
      "Epoch 442/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4899 - accuracy: 0.7373 - val_loss: 0.5219 - val_accuracy: 0.7073\n",
      "Epoch 443/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4902 - accuracy: 0.7434 - val_loss: 0.5218 - val_accuracy: 0.7073\n",
      "Epoch 444/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4889 - accuracy: 0.7434 - val_loss: 0.5218 - val_accuracy: 0.7154\n",
      "Epoch 445/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4890 - accuracy: 0.7475 - val_loss: 0.5220 - val_accuracy: 0.7154\n",
      "Epoch 446/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4885 - accuracy: 0.7373 - val_loss: 0.5219 - val_accuracy: 0.7154\n",
      "Epoch 447/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4884 - accuracy: 0.7393 - val_loss: 0.5217 - val_accuracy: 0.7154\n",
      "Epoch 448/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4879 - accuracy: 0.7413 - val_loss: 0.5215 - val_accuracy: 0.7154\n",
      "Epoch 449/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4882 - accuracy: 0.7373 - val_loss: 0.5215 - val_accuracy: 0.7236\n",
      "Epoch 450/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4874 - accuracy: 0.7393 - val_loss: 0.5214 - val_accuracy: 0.7236\n",
      "Epoch 451/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4874 - accuracy: 0.7454 - val_loss: 0.5212 - val_accuracy: 0.7154\n",
      "Epoch 452/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4868 - accuracy: 0.7434 - val_loss: 0.5212 - val_accuracy: 0.7317\n",
      "Epoch 453/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4867 - accuracy: 0.7454 - val_loss: 0.5212 - val_accuracy: 0.7317\n",
      "Epoch 454/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4864 - accuracy: 0.7434 - val_loss: 0.5210 - val_accuracy: 0.7236\n",
      "Epoch 455/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4873 - accuracy: 0.7413 - val_loss: 0.5210 - val_accuracy: 0.7317\n",
      "Epoch 456/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4860 - accuracy: 0.7454 - val_loss: 0.5211 - val_accuracy: 0.7317\n",
      "Epoch 457/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4859 - accuracy: 0.7413 - val_loss: 0.5209 - val_accuracy: 0.7317\n",
      "Epoch 458/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4854 - accuracy: 0.7475 - val_loss: 0.5207 - val_accuracy: 0.7236\n",
      "Epoch 459/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4857 - accuracy: 0.7475 - val_loss: 0.5206 - val_accuracy: 0.7317\n",
      "Epoch 460/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4855 - accuracy: 0.7495 - val_loss: 0.5208 - val_accuracy: 0.7317\n",
      "Epoch 461/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4860 - accuracy: 0.7475 - val_loss: 0.5208 - val_accuracy: 0.7317\n",
      "Epoch 462/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4848 - accuracy: 0.7454 - val_loss: 0.5206 - val_accuracy: 0.7317\n",
      "Epoch 463/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4844 - accuracy: 0.7475 - val_loss: 0.5208 - val_accuracy: 0.7398\n",
      "Epoch 464/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7454 - val_loss: 0.5206 - val_accuracy: 0.7317\n",
      "Epoch 465/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4840 - accuracy: 0.7454 - val_loss: 0.5207 - val_accuracy: 0.7317\n",
      "Epoch 466/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4835 - accuracy: 0.7475 - val_loss: 0.5206 - val_accuracy: 0.7317\n",
      "Epoch 467/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4834 - accuracy: 0.7475 - val_loss: 0.5206 - val_accuracy: 0.7398\n",
      "Epoch 468/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4833 - accuracy: 0.7536 - val_loss: 0.5208 - val_accuracy: 0.7398\n",
      "Epoch 469/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4834 - accuracy: 0.7495 - val_loss: 0.5205 - val_accuracy: 0.7317\n",
      "Epoch 470/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4826 - accuracy: 0.7495 - val_loss: 0.5203 - val_accuracy: 0.7317\n",
      "Epoch 471/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4826 - accuracy: 0.7536 - val_loss: 0.5203 - val_accuracy: 0.7317\n",
      "Epoch 472/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4824 - accuracy: 0.7536 - val_loss: 0.5202 - val_accuracy: 0.7317\n",
      "Epoch 473/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4821 - accuracy: 0.7495 - val_loss: 0.5202 - val_accuracy: 0.7317\n",
      "Epoch 474/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4823 - accuracy: 0.7536 - val_loss: 0.5201 - val_accuracy: 0.7317\n",
      "Epoch 475/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4824 - accuracy: 0.7515 - val_loss: 0.5202 - val_accuracy: 0.7398\n",
      "Epoch 476/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4815 - accuracy: 0.7536 - val_loss: 0.5201 - val_accuracy: 0.7398\n",
      "Epoch 477/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4820 - accuracy: 0.7536 - val_loss: 0.5200 - val_accuracy: 0.7317\n",
      "Epoch 478/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4815 - accuracy: 0.7536 - val_loss: 0.5201 - val_accuracy: 0.7398\n",
      "Epoch 479/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4818 - accuracy: 0.7536 - val_loss: 0.5201 - val_accuracy: 0.7398\n",
      "Epoch 480/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4808 - accuracy: 0.7536 - val_loss: 0.5199 - val_accuracy: 0.7317\n",
      "Epoch 481/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4806 - accuracy: 0.7576 - val_loss: 0.5199 - val_accuracy: 0.7398\n",
      "Epoch 482/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4809 - accuracy: 0.7536 - val_loss: 0.5199 - val_accuracy: 0.7317\n",
      "Epoch 483/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4803 - accuracy: 0.7495 - val_loss: 0.5198 - val_accuracy: 0.7317\n",
      "Epoch 484/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4801 - accuracy: 0.7576 - val_loss: 0.5198 - val_accuracy: 0.7317\n",
      "Epoch 485/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4802 - accuracy: 0.7515 - val_loss: 0.5198 - val_accuracy: 0.7398\n",
      "Epoch 486/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4804 - accuracy: 0.7556 - val_loss: 0.5197 - val_accuracy: 0.7317\n",
      "Epoch 487/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4794 - accuracy: 0.7536 - val_loss: 0.5197 - val_accuracy: 0.7317\n",
      "Epoch 488/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4793 - accuracy: 0.7556 - val_loss: 0.5197 - val_accuracy: 0.7398\n",
      "Epoch 489/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4805 - accuracy: 0.7495 - val_loss: 0.5199 - val_accuracy: 0.7398\n",
      "Epoch 490/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4791 - accuracy: 0.7576 - val_loss: 0.5197 - val_accuracy: 0.7317\n",
      "Epoch 491/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4793 - accuracy: 0.7536 - val_loss: 0.5196 - val_accuracy: 0.7398\n",
      "Epoch 492/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4784 - accuracy: 0.7536 - val_loss: 0.5196 - val_accuracy: 0.7398\n",
      "Epoch 493/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4784 - accuracy: 0.7556 - val_loss: 0.5197 - val_accuracy: 0.7398\n",
      "Epoch 494/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4784 - accuracy: 0.7597 - val_loss: 0.5196 - val_accuracy: 0.7398\n",
      "Epoch 495/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4779 - accuracy: 0.7536 - val_loss: 0.5197 - val_accuracy: 0.7398\n",
      "Epoch 496/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4776 - accuracy: 0.7617 - val_loss: 0.5196 - val_accuracy: 0.7317\n",
      "Epoch 497/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4781 - accuracy: 0.7617 - val_loss: 0.5195 - val_accuracy: 0.7317\n",
      "Epoch 498/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4779 - accuracy: 0.7576 - val_loss: 0.5196 - val_accuracy: 0.7398\n",
      "Epoch 499/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4775 - accuracy: 0.7576 - val_loss: 0.5196 - val_accuracy: 0.7398\n",
      "Epoch 500/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4776 - accuracy: 0.7576 - val_loss: 0.5196 - val_accuracy: 0.7398\n",
      "Epoch 501/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4775 - accuracy: 0.7597 - val_loss: 0.5196 - val_accuracy: 0.7480\n",
      "Epoch 502/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4773 - accuracy: 0.7576 - val_loss: 0.5196 - val_accuracy: 0.7480\n",
      "Epoch 503/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4770 - accuracy: 0.7597 - val_loss: 0.5196 - val_accuracy: 0.7480\n",
      "Epoch 504/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4767 - accuracy: 0.7576 - val_loss: 0.5195 - val_accuracy: 0.7398\n",
      "Epoch 505/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4762 - accuracy: 0.7617 - val_loss: 0.5195 - val_accuracy: 0.7398\n",
      "Epoch 506/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4764 - accuracy: 0.7617 - val_loss: 0.5194 - val_accuracy: 0.7398\n",
      "Epoch 507/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4759 - accuracy: 0.7637 - val_loss: 0.5194 - val_accuracy: 0.7398\n",
      "Epoch 508/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4761 - accuracy: 0.7597 - val_loss: 0.5194 - val_accuracy: 0.7398\n",
      "Epoch 509/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4771 - accuracy: 0.7515 - val_loss: 0.5194 - val_accuracy: 0.7398\n",
      "Epoch 510/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4770 - accuracy: 0.7576 - val_loss: 0.5194 - val_accuracy: 0.7398\n",
      "Epoch 511/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4759 - accuracy: 0.7597 - val_loss: 0.5194 - val_accuracy: 0.7398\n",
      "Epoch 512/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4749 - accuracy: 0.7617 - val_loss: 0.5194 - val_accuracy: 0.7480\n",
      "Epoch 513/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4756 - accuracy: 0.7637 - val_loss: 0.5195 - val_accuracy: 0.7480\n",
      "Epoch 514/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4753 - accuracy: 0.7597 - val_loss: 0.5196 - val_accuracy: 0.7480\n",
      "Epoch 515/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4750 - accuracy: 0.7637 - val_loss: 0.5195 - val_accuracy: 0.7480\n",
      "Epoch 516/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4744 - accuracy: 0.7617 - val_loss: 0.5194 - val_accuracy: 0.7480\n",
      "Epoch 517/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4746 - accuracy: 0.7637 - val_loss: 0.5194 - val_accuracy: 0.7480\n",
      "Epoch 518/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4751 - accuracy: 0.7637 - val_loss: 0.5194 - val_accuracy: 0.7398\n",
      "Epoch 519/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4747 - accuracy: 0.7617 - val_loss: 0.5194 - val_accuracy: 0.7561\n",
      "Epoch 520/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4742 - accuracy: 0.7617 - val_loss: 0.5194 - val_accuracy: 0.7480\n",
      "Epoch 521/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4748 - accuracy: 0.7617 - val_loss: 0.5194 - val_accuracy: 0.7480\n",
      "Epoch 522/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4738 - accuracy: 0.7576 - val_loss: 0.5194 - val_accuracy: 0.7480\n",
      "Epoch 523/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4738 - accuracy: 0.7637 - val_loss: 0.5194 - val_accuracy: 0.7480\n",
      "Epoch 524/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4738 - accuracy: 0.7597 - val_loss: 0.5196 - val_accuracy: 0.7480\n",
      "Epoch 525/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4734 - accuracy: 0.7617 - val_loss: 0.5197 - val_accuracy: 0.7480\n",
      "Epoch 526/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4735 - accuracy: 0.7658 - val_loss: 0.5195 - val_accuracy: 0.7480\n",
      "Epoch 527/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4731 - accuracy: 0.7678 - val_loss: 0.5194 - val_accuracy: 0.7561\n",
      "Epoch 528/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4728 - accuracy: 0.7617 - val_loss: 0.5195 - val_accuracy: 0.7480\n",
      "Epoch 529/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4730 - accuracy: 0.7637 - val_loss: 0.5194 - val_accuracy: 0.7561\n",
      "Epoch 530/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4726 - accuracy: 0.7617 - val_loss: 0.5195 - val_accuracy: 0.7480\n",
      "Epoch 531/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4723 - accuracy: 0.7617 - val_loss: 0.5195 - val_accuracy: 0.7561\n",
      "Epoch 532/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4723 - accuracy: 0.7637 - val_loss: 0.5196 - val_accuracy: 0.7480\n",
      "Epoch 533/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4726 - accuracy: 0.7637 - val_loss: 0.5195 - val_accuracy: 0.7480\n",
      "Epoch 534/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4721 - accuracy: 0.7617 - val_loss: 0.5195 - val_accuracy: 0.7480\n",
      "Epoch 535/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4727 - accuracy: 0.7617 - val_loss: 0.5197 - val_accuracy: 0.7480\n",
      "Epoch 536/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4721 - accuracy: 0.7678 - val_loss: 0.5200 - val_accuracy: 0.7480\n",
      "Epoch 537/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4721 - accuracy: 0.7658 - val_loss: 0.5197 - val_accuracy: 0.7480\n",
      "Epoch 538/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4716 - accuracy: 0.7678 - val_loss: 0.5196 - val_accuracy: 0.7480\n",
      "Epoch 539/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4720 - accuracy: 0.7760 - val_loss: 0.5196 - val_accuracy: 0.7561\n",
      "Epoch 540/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4718 - accuracy: 0.7658 - val_loss: 0.5196 - val_accuracy: 0.7561\n",
      "Epoch 541/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4713 - accuracy: 0.7678 - val_loss: 0.5196 - val_accuracy: 0.7480\n",
      "Epoch 542/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4713 - accuracy: 0.7597 - val_loss: 0.5197 - val_accuracy: 0.7480\n",
      "Epoch 543/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4715 - accuracy: 0.7658 - val_loss: 0.5196 - val_accuracy: 0.7561\n",
      "Epoch 544/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4717 - accuracy: 0.7699 - val_loss: 0.5197 - val_accuracy: 0.7480\n",
      "Epoch 545/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4709 - accuracy: 0.7719 - val_loss: 0.5197 - val_accuracy: 0.7480\n",
      "Epoch 546/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4705 - accuracy: 0.7719 - val_loss: 0.5196 - val_accuracy: 0.7561\n",
      "Epoch 547/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4708 - accuracy: 0.7658 - val_loss: 0.5197 - val_accuracy: 0.7480\n",
      "Epoch 548/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.7678 - val_loss: 0.5197 - val_accuracy: 0.7561\n",
      "Epoch 549/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4706 - accuracy: 0.7678 - val_loss: 0.5197 - val_accuracy: 0.7561\n",
      "Epoch 550/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4699 - accuracy: 0.7658 - val_loss: 0.5198 - val_accuracy: 0.7561\n",
      "Epoch 551/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4703 - accuracy: 0.7719 - val_loss: 0.5198 - val_accuracy: 0.7480\n",
      "Epoch 552/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4708 - accuracy: 0.7617 - val_loss: 0.5198 - val_accuracy: 0.7480\n",
      "Epoch 553/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7678 - val_loss: 0.5198 - val_accuracy: 0.7561\n",
      "Epoch 554/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4698 - accuracy: 0.7699 - val_loss: 0.5199 - val_accuracy: 0.7480\n",
      "Epoch 555/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4702 - accuracy: 0.7637 - val_loss: 0.5199 - val_accuracy: 0.7480\n",
      "Epoch 556/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4690 - accuracy: 0.7699 - val_loss: 0.5199 - val_accuracy: 0.7480\n",
      "Epoch 557/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4697 - accuracy: 0.7678 - val_loss: 0.5199 - val_accuracy: 0.7561\n",
      "Epoch 558/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7678 - val_loss: 0.5199 - val_accuracy: 0.7561\n",
      "Epoch 559/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4690 - accuracy: 0.7678 - val_loss: 0.5199 - val_accuracy: 0.7480\n",
      "Epoch 560/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4692 - accuracy: 0.7678 - val_loss: 0.5200 - val_accuracy: 0.7480\n",
      "Epoch 561/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4688 - accuracy: 0.7637 - val_loss: 0.5201 - val_accuracy: 0.7480\n",
      "Epoch 562/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4692 - accuracy: 0.7699 - val_loss: 0.5199 - val_accuracy: 0.7561\n",
      "Epoch 563/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4688 - accuracy: 0.7678 - val_loss: 0.5199 - val_accuracy: 0.7561\n",
      "Epoch 564/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4693 - accuracy: 0.7678 - val_loss: 0.5199 - val_accuracy: 0.7480\n",
      "Epoch 565/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4682 - accuracy: 0.7678 - val_loss: 0.5201 - val_accuracy: 0.7480\n",
      "Epoch 566/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4689 - accuracy: 0.7678 - val_loss: 0.5200 - val_accuracy: 0.7561\n",
      "Epoch 567/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4681 - accuracy: 0.7678 - val_loss: 0.5200 - val_accuracy: 0.7561\n",
      "Epoch 568/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.7658 - val_loss: 0.5200 - val_accuracy: 0.7480\n",
      "Epoch 569/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.7678 - val_loss: 0.5203 - val_accuracy: 0.7480\n",
      "Epoch 570/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4682 - accuracy: 0.7699 - val_loss: 0.5200 - val_accuracy: 0.7561\n",
      "Epoch 571/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4680 - accuracy: 0.7637 - val_loss: 0.5200 - val_accuracy: 0.7561\n",
      "Epoch 572/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4686 - accuracy: 0.7739 - val_loss: 0.5200 - val_accuracy: 0.7480\n",
      "Epoch 573/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7678 - val_loss: 0.5200 - val_accuracy: 0.7561\n",
      "Epoch 574/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4676 - accuracy: 0.7658 - val_loss: 0.5200 - val_accuracy: 0.7480\n",
      "Epoch 575/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.7678 - val_loss: 0.5203 - val_accuracy: 0.7480\n",
      "Epoch 576/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4677 - accuracy: 0.7719 - val_loss: 0.5203 - val_accuracy: 0.7480\n",
      "Epoch 577/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7658 - val_loss: 0.5201 - val_accuracy: 0.7561\n",
      "Epoch 578/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.7719 - val_loss: 0.5201 - val_accuracy: 0.7561\n",
      "Epoch 579/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4675 - accuracy: 0.7678 - val_loss: 0.5201 - val_accuracy: 0.7561\n",
      "Epoch 580/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4672 - accuracy: 0.7699 - val_loss: 0.5202 - val_accuracy: 0.7561\n",
      "Epoch 581/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7678 - val_loss: 0.5202 - val_accuracy: 0.7561\n",
      "Epoch 582/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7719 - val_loss: 0.5201 - val_accuracy: 0.7561\n",
      "Epoch 583/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7699 - val_loss: 0.5201 - val_accuracy: 0.7561\n",
      "Epoch 584/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4670 - accuracy: 0.7678 - val_loss: 0.5201 - val_accuracy: 0.7561\n",
      "Epoch 585/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4666 - accuracy: 0.7678 - val_loss: 0.5201 - val_accuracy: 0.7561\n",
      "Epoch 586/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7699 - val_loss: 0.5201 - val_accuracy: 0.7561\n",
      "Epoch 587/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7678 - val_loss: 0.5203 - val_accuracy: 0.7480\n",
      "Epoch 588/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7699 - val_loss: 0.5202 - val_accuracy: 0.7561\n",
      "Epoch 589/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7760 - val_loss: 0.5202 - val_accuracy: 0.7561\n",
      "Epoch 590/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7699 - val_loss: 0.5202 - val_accuracy: 0.7642\n",
      "Epoch 591/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7678 - val_loss: 0.5202 - val_accuracy: 0.7642\n",
      "Epoch 592/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7719 - val_loss: 0.5202 - val_accuracy: 0.7642\n",
      "Epoch 593/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4655 - accuracy: 0.7699 - val_loss: 0.5203 - val_accuracy: 0.7480\n",
      "Epoch 594/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7658 - val_loss: 0.5203 - val_accuracy: 0.7561\n",
      "Epoch 595/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7658 - val_loss: 0.5202 - val_accuracy: 0.7561\n",
      "Epoch 596/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7719 - val_loss: 0.5204 - val_accuracy: 0.7480\n",
      "Epoch 597/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7699 - val_loss: 0.5203 - val_accuracy: 0.7642\n",
      "Epoch 598/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7699 - val_loss: 0.5203 - val_accuracy: 0.7642\n",
      "Epoch 599/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.7699 - val_loss: 0.5203 - val_accuracy: 0.7561\n",
      "Epoch 600/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.7678 - val_loss: 0.5203 - val_accuracy: 0.7642\n",
      "Epoch 601/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7658 - val_loss: 0.5203 - val_accuracy: 0.7561\n",
      "Epoch 602/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7699 - val_loss: 0.5203 - val_accuracy: 0.7642\n",
      "Epoch 603/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7699 - val_loss: 0.5203 - val_accuracy: 0.7642\n",
      "Epoch 604/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4647 - accuracy: 0.7658 - val_loss: 0.5203 - val_accuracy: 0.7642\n",
      "Epoch 605/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7699 - val_loss: 0.5205 - val_accuracy: 0.7480\n",
      "Epoch 606/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4644 - accuracy: 0.7678 - val_loss: 0.5204 - val_accuracy: 0.7480\n",
      "Epoch 607/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.7678 - val_loss: 0.5206 - val_accuracy: 0.7480\n",
      "Epoch 608/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.7739 - val_loss: 0.5205 - val_accuracy: 0.7480\n",
      "Epoch 609/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4647 - accuracy: 0.7719 - val_loss: 0.5204 - val_accuracy: 0.7642\n",
      "Epoch 610/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4639 - accuracy: 0.7678 - val_loss: 0.5204 - val_accuracy: 0.7642\n",
      "Epoch 611/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4641 - accuracy: 0.7678 - val_loss: 0.5204 - val_accuracy: 0.7642\n",
      "Epoch 612/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4647 - accuracy: 0.7678 - val_loss: 0.5206 - val_accuracy: 0.7480\n",
      "Epoch 613/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4646 - accuracy: 0.7637 - val_loss: 0.5206 - val_accuracy: 0.7480\n",
      "Epoch 614/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4640 - accuracy: 0.7821 - val_loss: 0.5205 - val_accuracy: 0.7561\n",
      "Epoch 615/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4638 - accuracy: 0.7719 - val_loss: 0.5207 - val_accuracy: 0.7480\n",
      "Epoch 616/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7739 - val_loss: 0.5206 - val_accuracy: 0.7480\n",
      "Epoch 617/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4641 - accuracy: 0.7739 - val_loss: 0.5205 - val_accuracy: 0.7642\n",
      "Epoch 618/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4638 - accuracy: 0.7699 - val_loss: 0.5205 - val_accuracy: 0.7642\n",
      "Epoch 619/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4644 - accuracy: 0.7739 - val_loss: 0.5205 - val_accuracy: 0.7561\n",
      "Epoch 620/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4640 - accuracy: 0.7739 - val_loss: 0.5206 - val_accuracy: 0.7561\n",
      "Epoch 621/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4635 - accuracy: 0.7678 - val_loss: 0.5205 - val_accuracy: 0.7642\n",
      "Epoch 622/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4637 - accuracy: 0.7719 - val_loss: 0.5205 - val_accuracy: 0.7561\n",
      "Epoch 623/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4632 - accuracy: 0.7719 - val_loss: 0.5206 - val_accuracy: 0.7561\n",
      "Epoch 624/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4644 - accuracy: 0.7719 - val_loss: 0.5206 - val_accuracy: 0.7642\n",
      "Epoch 625/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4636 - accuracy: 0.7678 - val_loss: 0.5206 - val_accuracy: 0.7561\n",
      "Epoch 626/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4631 - accuracy: 0.7658 - val_loss: 0.5206 - val_accuracy: 0.7561\n",
      "Epoch 627/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4630 - accuracy: 0.7699 - val_loss: 0.5206 - val_accuracy: 0.7642\n",
      "Epoch 628/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4631 - accuracy: 0.7699 - val_loss: 0.5206 - val_accuracy: 0.7642\n",
      "Epoch 629/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4632 - accuracy: 0.7739 - val_loss: 0.5208 - val_accuracy: 0.7561\n",
      "Epoch 630/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4638 - accuracy: 0.7739 - val_loss: 0.5206 - val_accuracy: 0.7642\n",
      "Epoch 631/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4625 - accuracy: 0.7699 - val_loss: 0.5208 - val_accuracy: 0.7561\n",
      "Epoch 632/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4633 - accuracy: 0.7760 - val_loss: 0.5212 - val_accuracy: 0.7398\n",
      "Epoch 633/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4631 - accuracy: 0.7719 - val_loss: 0.5208 - val_accuracy: 0.7561\n",
      "Epoch 634/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4633 - accuracy: 0.7719 - val_loss: 0.5207 - val_accuracy: 0.7642\n",
      "Epoch 635/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4631 - accuracy: 0.7637 - val_loss: 0.5207 - val_accuracy: 0.7642\n",
      "Epoch 636/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4632 - accuracy: 0.7699 - val_loss: 0.5207 - val_accuracy: 0.7642\n",
      "Epoch 637/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4625 - accuracy: 0.7760 - val_loss: 0.5207 - val_accuracy: 0.7642\n",
      "Epoch 638/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4630 - accuracy: 0.7739 - val_loss: 0.5207 - val_accuracy: 0.7561\n",
      "Epoch 639/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4624 - accuracy: 0.7719 - val_loss: 0.5207 - val_accuracy: 0.7561\n",
      "Epoch 640/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4635 - accuracy: 0.7719 - val_loss: 0.5207 - val_accuracy: 0.7561\n",
      "Epoch 641/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4623 - accuracy: 0.7719 - val_loss: 0.5208 - val_accuracy: 0.7642\n",
      "Epoch 642/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4628 - accuracy: 0.7780 - val_loss: 0.5207 - val_accuracy: 0.7561\n",
      "Epoch 643/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4616 - accuracy: 0.7699 - val_loss: 0.5208 - val_accuracy: 0.7561\n",
      "Epoch 644/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.7739 - val_loss: 0.5207 - val_accuracy: 0.7642\n",
      "Epoch 645/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4620 - accuracy: 0.7699 - val_loss: 0.5206 - val_accuracy: 0.7642\n",
      "Epoch 646/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4630 - accuracy: 0.7739 - val_loss: 0.5206 - val_accuracy: 0.7561\n",
      "Epoch 647/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4619 - accuracy: 0.7699 - val_loss: 0.5206 - val_accuracy: 0.7561\n",
      "Epoch 648/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4612 - accuracy: 0.7760 - val_loss: 0.5206 - val_accuracy: 0.7642\n",
      "Epoch 649/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4613 - accuracy: 0.7739 - val_loss: 0.5205 - val_accuracy: 0.7642\n",
      "Epoch 650/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4619 - accuracy: 0.7739 - val_loss: 0.5205 - val_accuracy: 0.7642\n",
      "Epoch 651/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4614 - accuracy: 0.7699 - val_loss: 0.5205 - val_accuracy: 0.7642\n",
      "Epoch 652/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4611 - accuracy: 0.7719 - val_loss: 0.5204 - val_accuracy: 0.7642\n",
      "Epoch 653/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4610 - accuracy: 0.7658 - val_loss: 0.5204 - val_accuracy: 0.7642\n",
      "Epoch 654/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4612 - accuracy: 0.7658 - val_loss: 0.5203 - val_accuracy: 0.7642\n",
      "Epoch 655/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4615 - accuracy: 0.7699 - val_loss: 0.5203 - val_accuracy: 0.7642\n",
      "Epoch 656/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4608 - accuracy: 0.7678 - val_loss: 0.5203 - val_accuracy: 0.7642\n",
      "Epoch 657/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4616 - accuracy: 0.7760 - val_loss: 0.5204 - val_accuracy: 0.7642\n",
      "Epoch 658/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4612 - accuracy: 0.7719 - val_loss: 0.5204 - val_accuracy: 0.7642\n",
      "Epoch 659/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4609 - accuracy: 0.7739 - val_loss: 0.5202 - val_accuracy: 0.7642\n",
      "Epoch 660/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4614 - accuracy: 0.7719 - val_loss: 0.5202 - val_accuracy: 0.7642\n",
      "Epoch 661/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4608 - accuracy: 0.7699 - val_loss: 0.5202 - val_accuracy: 0.7642\n",
      "Epoch 662/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4610 - accuracy: 0.7699 - val_loss: 0.5203 - val_accuracy: 0.7561\n",
      "Epoch 663/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4613 - accuracy: 0.7719 - val_loss: 0.5201 - val_accuracy: 0.7642\n",
      "Epoch 664/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4602 - accuracy: 0.7739 - val_loss: 0.5201 - val_accuracy: 0.7642\n",
      "Epoch 665/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4605 - accuracy: 0.7739 - val_loss: 0.5200 - val_accuracy: 0.7642\n",
      "Epoch 666/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.7760 - val_loss: 0.5200 - val_accuracy: 0.7642\n",
      "Epoch 667/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4608 - accuracy: 0.7719 - val_loss: 0.5199 - val_accuracy: 0.7642\n",
      "Epoch 668/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4603 - accuracy: 0.7739 - val_loss: 0.5199 - val_accuracy: 0.7642\n",
      "Epoch 669/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4615 - accuracy: 0.7760 - val_loss: 0.5198 - val_accuracy: 0.7642\n",
      "Epoch 670/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4606 - accuracy: 0.7719 - val_loss: 0.5198 - val_accuracy: 0.7724\n",
      "Epoch 671/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4610 - accuracy: 0.7760 - val_loss: 0.5197 - val_accuracy: 0.7642\n",
      "Epoch 672/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4613 - accuracy: 0.7760 - val_loss: 0.5197 - val_accuracy: 0.7480\n",
      "Epoch 673/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4604 - accuracy: 0.7760 - val_loss: 0.5196 - val_accuracy: 0.7480\n",
      "Epoch 674/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4599 - accuracy: 0.7719 - val_loss: 0.5196 - val_accuracy: 0.7480\n",
      "Epoch 675/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4606 - accuracy: 0.7760 - val_loss: 0.5195 - val_accuracy: 0.7642\n",
      "Epoch 676/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4595 - accuracy: 0.7719 - val_loss: 0.5194 - val_accuracy: 0.7642\n",
      "Epoch 677/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4598 - accuracy: 0.7739 - val_loss: 0.5194 - val_accuracy: 0.7480\n",
      "Epoch 678/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4600 - accuracy: 0.7780 - val_loss: 0.5193 - val_accuracy: 0.7480\n",
      "Epoch 679/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4596 - accuracy: 0.7780 - val_loss: 0.5192 - val_accuracy: 0.7724\n",
      "Epoch 680/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4594 - accuracy: 0.7800 - val_loss: 0.5190 - val_accuracy: 0.7642\n",
      "Epoch 681/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4590 - accuracy: 0.7760 - val_loss: 0.5189 - val_accuracy: 0.7561\n",
      "Epoch 682/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4590 - accuracy: 0.7760 - val_loss: 0.5188 - val_accuracy: 0.7642\n",
      "Epoch 683/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4596 - accuracy: 0.7780 - val_loss: 0.5187 - val_accuracy: 0.7561\n",
      "Epoch 684/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4592 - accuracy: 0.7800 - val_loss: 0.5185 - val_accuracy: 0.7561\n",
      "Epoch 685/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.7760 - val_loss: 0.5184 - val_accuracy: 0.7561\n",
      "Epoch 686/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4588 - accuracy: 0.7821 - val_loss: 0.5183 - val_accuracy: 0.7561\n",
      "Epoch 687/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4589 - accuracy: 0.7800 - val_loss: 0.5182 - val_accuracy: 0.7561\n",
      "Epoch 688/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4585 - accuracy: 0.7780 - val_loss: 0.5184 - val_accuracy: 0.7805\n",
      "Epoch 689/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4584 - accuracy: 0.7821 - val_loss: 0.5180 - val_accuracy: 0.7561\n",
      "Epoch 690/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4586 - accuracy: 0.7800 - val_loss: 0.5181 - val_accuracy: 0.7724\n",
      "Epoch 691/800\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4588 - accuracy: 0.7800 - val_loss: 0.5179 - val_accuracy: 0.7642\n",
      "Epoch 692/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4589 - accuracy: 0.7780 - val_loss: 0.5179 - val_accuracy: 0.7805\n",
      "Epoch 693/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4588 - accuracy: 0.7780 - val_loss: 0.5177 - val_accuracy: 0.7642\n",
      "Epoch 694/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4580 - accuracy: 0.7780 - val_loss: 0.5175 - val_accuracy: 0.7561\n",
      "Epoch 695/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4580 - accuracy: 0.7800 - val_loss: 0.5176 - val_accuracy: 0.7724\n",
      "Epoch 696/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4587 - accuracy: 0.7821 - val_loss: 0.5174 - val_accuracy: 0.7642\n",
      "Epoch 697/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4577 - accuracy: 0.7821 - val_loss: 0.5172 - val_accuracy: 0.7561\n",
      "Epoch 698/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4574 - accuracy: 0.7780 - val_loss: 0.5171 - val_accuracy: 0.7561\n",
      "Epoch 699/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4581 - accuracy: 0.7800 - val_loss: 0.5171 - val_accuracy: 0.7724\n",
      "Epoch 700/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4574 - accuracy: 0.7821 - val_loss: 0.5171 - val_accuracy: 0.7480\n",
      "Epoch 701/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.7719 - val_loss: 0.5169 - val_accuracy: 0.7561\n",
      "Epoch 702/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4576 - accuracy: 0.7800 - val_loss: 0.5173 - val_accuracy: 0.7398\n",
      "Epoch 703/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7760 - val_loss: 0.5171 - val_accuracy: 0.7398\n",
      "Epoch 704/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4575 - accuracy: 0.7780 - val_loss: 0.5171 - val_accuracy: 0.7398\n",
      "Epoch 705/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4580 - accuracy: 0.7739 - val_loss: 0.5168 - val_accuracy: 0.7480\n",
      "Epoch 706/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4581 - accuracy: 0.7780 - val_loss: 0.5169 - val_accuracy: 0.7724\n",
      "Epoch 707/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4581 - accuracy: 0.7821 - val_loss: 0.5167 - val_accuracy: 0.7642\n",
      "Epoch 708/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4567 - accuracy: 0.7841 - val_loss: 0.5169 - val_accuracy: 0.7480\n",
      "Epoch 709/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4571 - accuracy: 0.7800 - val_loss: 0.5168 - val_accuracy: 0.7642\n",
      "Epoch 710/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4569 - accuracy: 0.7821 - val_loss: 0.5167 - val_accuracy: 0.7561\n",
      "Epoch 711/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4577 - accuracy: 0.7780 - val_loss: 0.5168 - val_accuracy: 0.7724\n",
      "Epoch 712/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4573 - accuracy: 0.7821 - val_loss: 0.5167 - val_accuracy: 0.7642\n",
      "Epoch 713/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4566 - accuracy: 0.7800 - val_loss: 0.5167 - val_accuracy: 0.7480\n",
      "Epoch 714/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4566 - accuracy: 0.7780 - val_loss: 0.5166 - val_accuracy: 0.7642\n",
      "Epoch 715/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4577 - accuracy: 0.7800 - val_loss: 0.5165 - val_accuracy: 0.7642\n",
      "Epoch 716/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4561 - accuracy: 0.7821 - val_loss: 0.5165 - val_accuracy: 0.7480\n",
      "Epoch 717/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4564 - accuracy: 0.7821 - val_loss: 0.5165 - val_accuracy: 0.7561\n",
      "Epoch 718/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4568 - accuracy: 0.7780 - val_loss: 0.5167 - val_accuracy: 0.7724\n",
      "Epoch 719/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4569 - accuracy: 0.7821 - val_loss: 0.5165 - val_accuracy: 0.7724\n",
      "Epoch 720/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4560 - accuracy: 0.7882 - val_loss: 0.5169 - val_accuracy: 0.7398\n",
      "Epoch 721/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4570 - accuracy: 0.7760 - val_loss: 0.5167 - val_accuracy: 0.7480\n",
      "Epoch 722/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4565 - accuracy: 0.7841 - val_loss: 0.5165 - val_accuracy: 0.7561\n",
      "Epoch 723/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.7760 - val_loss: 0.5165 - val_accuracy: 0.7642\n",
      "Epoch 724/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4558 - accuracy: 0.7821 - val_loss: 0.5165 - val_accuracy: 0.7642\n",
      "Epoch 725/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4563 - accuracy: 0.7780 - val_loss: 0.5164 - val_accuracy: 0.7642\n",
      "Epoch 726/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4560 - accuracy: 0.7800 - val_loss: 0.5165 - val_accuracy: 0.7480\n",
      "Epoch 727/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4560 - accuracy: 0.7800 - val_loss: 0.5165 - val_accuracy: 0.7642\n",
      "Epoch 728/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4560 - accuracy: 0.7780 - val_loss: 0.5166 - val_accuracy: 0.7480\n",
      "Epoch 729/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4561 - accuracy: 0.7780 - val_loss: 0.5166 - val_accuracy: 0.7480\n",
      "Epoch 730/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4562 - accuracy: 0.7800 - val_loss: 0.5168 - val_accuracy: 0.7398\n",
      "Epoch 731/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4554 - accuracy: 0.7800 - val_loss: 0.5165 - val_accuracy: 0.7724\n",
      "Epoch 732/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4554 - accuracy: 0.7739 - val_loss: 0.5165 - val_accuracy: 0.7724\n",
      "Epoch 733/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4557 - accuracy: 0.7841 - val_loss: 0.5166 - val_accuracy: 0.7480\n",
      "Epoch 734/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4551 - accuracy: 0.7780 - val_loss: 0.5166 - val_accuracy: 0.7561\n",
      "Epoch 735/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4555 - accuracy: 0.7800 - val_loss: 0.5168 - val_accuracy: 0.7805\n",
      "Epoch 736/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4550 - accuracy: 0.7760 - val_loss: 0.5166 - val_accuracy: 0.7724\n",
      "Epoch 737/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4560 - accuracy: 0.7821 - val_loss: 0.5166 - val_accuracy: 0.7642\n",
      "Epoch 738/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.7780 - val_loss: 0.5168 - val_accuracy: 0.7724\n",
      "Epoch 739/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4554 - accuracy: 0.7821 - val_loss: 0.5166 - val_accuracy: 0.7724\n",
      "Epoch 740/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4549 - accuracy: 0.7841 - val_loss: 0.5166 - val_accuracy: 0.7724\n",
      "Epoch 741/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4547 - accuracy: 0.7821 - val_loss: 0.5166 - val_accuracy: 0.7724\n",
      "Epoch 742/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4555 - accuracy: 0.7862 - val_loss: 0.5167 - val_accuracy: 0.7561\n",
      "Epoch 743/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4548 - accuracy: 0.7821 - val_loss: 0.5166 - val_accuracy: 0.7642\n",
      "Epoch 744/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4546 - accuracy: 0.7862 - val_loss: 0.5166 - val_accuracy: 0.7642\n",
      "Epoch 745/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4563 - accuracy: 0.7780 - val_loss: 0.5166 - val_accuracy: 0.7561\n",
      "Epoch 746/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4546 - accuracy: 0.7821 - val_loss: 0.5166 - val_accuracy: 0.7561\n",
      "Epoch 747/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4541 - accuracy: 0.7780 - val_loss: 0.5165 - val_accuracy: 0.7724\n",
      "Epoch 748/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4556 - accuracy: 0.7841 - val_loss: 0.5166 - val_accuracy: 0.7561\n",
      "Epoch 749/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4546 - accuracy: 0.7821 - val_loss: 0.5165 - val_accuracy: 0.7724\n",
      "Epoch 750/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4550 - accuracy: 0.7821 - val_loss: 0.5166 - val_accuracy: 0.7724\n",
      "Epoch 751/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4539 - accuracy: 0.7862 - val_loss: 0.5165 - val_accuracy: 0.7724\n",
      "Epoch 752/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4541 - accuracy: 0.7800 - val_loss: 0.5166 - val_accuracy: 0.7724\n",
      "Epoch 753/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4542 - accuracy: 0.7841 - val_loss: 0.5169 - val_accuracy: 0.7805\n",
      "Epoch 754/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4545 - accuracy: 0.7862 - val_loss: 0.5166 - val_accuracy: 0.7724\n",
      "Epoch 755/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4539 - accuracy: 0.7821 - val_loss: 0.5167 - val_accuracy: 0.7724\n",
      "Epoch 756/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4539 - accuracy: 0.7821 - val_loss: 0.5167 - val_accuracy: 0.7724\n",
      "Epoch 757/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4545 - accuracy: 0.7862 - val_loss: 0.5167 - val_accuracy: 0.7561\n",
      "Epoch 758/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4543 - accuracy: 0.7841 - val_loss: 0.5166 - val_accuracy: 0.7724\n",
      "Epoch 759/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4556 - accuracy: 0.7882 - val_loss: 0.5169 - val_accuracy: 0.7480\n",
      "Epoch 760/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4541 - accuracy: 0.7821 - val_loss: 0.5166 - val_accuracy: 0.7724\n",
      "Epoch 761/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4541 - accuracy: 0.7821 - val_loss: 0.5168 - val_accuracy: 0.7724\n",
      "Epoch 762/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4543 - accuracy: 0.7841 - val_loss: 0.5167 - val_accuracy: 0.7724\n",
      "Epoch 763/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4541 - accuracy: 0.7821 - val_loss: 0.5170 - val_accuracy: 0.7480\n",
      "Epoch 764/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4539 - accuracy: 0.7821 - val_loss: 0.5168 - val_accuracy: 0.7561\n",
      "Epoch 765/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4540 - accuracy: 0.7800 - val_loss: 0.5167 - val_accuracy: 0.7724\n",
      "Epoch 766/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4538 - accuracy: 0.7821 - val_loss: 0.5167 - val_accuracy: 0.7724\n",
      "Epoch 767/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4538 - accuracy: 0.7862 - val_loss: 0.5168 - val_accuracy: 0.7642\n",
      "Epoch 768/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4533 - accuracy: 0.7862 - val_loss: 0.5169 - val_accuracy: 0.7561\n",
      "Epoch 769/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4531 - accuracy: 0.7841 - val_loss: 0.5168 - val_accuracy: 0.7561\n",
      "Epoch 770/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4541 - accuracy: 0.7821 - val_loss: 0.5168 - val_accuracy: 0.7561\n",
      "Epoch 771/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4530 - accuracy: 0.7780 - val_loss: 0.5168 - val_accuracy: 0.7561\n",
      "Epoch 772/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4533 - accuracy: 0.7800 - val_loss: 0.5168 - val_accuracy: 0.7724\n",
      "Epoch 773/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4535 - accuracy: 0.7841 - val_loss: 0.5174 - val_accuracy: 0.7398\n",
      "Epoch 774/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4541 - accuracy: 0.7821 - val_loss: 0.5172 - val_accuracy: 0.7480\n",
      "Epoch 775/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4537 - accuracy: 0.7821 - val_loss: 0.5169 - val_accuracy: 0.7561\n",
      "Epoch 776/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4531 - accuracy: 0.7862 - val_loss: 0.5168 - val_accuracy: 0.7724\n",
      "Epoch 777/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4531 - accuracy: 0.7862 - val_loss: 0.5169 - val_accuracy: 0.7561\n",
      "Epoch 778/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4543 - accuracy: 0.7780 - val_loss: 0.5168 - val_accuracy: 0.7724\n",
      "Epoch 779/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4525 - accuracy: 0.7821 - val_loss: 0.5168 - val_accuracy: 0.7724\n",
      "Epoch 780/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4531 - accuracy: 0.7760 - val_loss: 0.5175 - val_accuracy: 0.7398\n",
      "Epoch 781/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4526 - accuracy: 0.7780 - val_loss: 0.5168 - val_accuracy: 0.7724\n",
      "Epoch 782/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4528 - accuracy: 0.7821 - val_loss: 0.5168 - val_accuracy: 0.7724\n",
      "Epoch 783/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4526 - accuracy: 0.7800 - val_loss: 0.5171 - val_accuracy: 0.7805\n",
      "Epoch 784/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4537 - accuracy: 0.7800 - val_loss: 0.5169 - val_accuracy: 0.7724\n",
      "Epoch 785/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4523 - accuracy: 0.7821 - val_loss: 0.5169 - val_accuracy: 0.7724\n",
      "Epoch 786/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4531 - accuracy: 0.7821 - val_loss: 0.5169 - val_accuracy: 0.7724\n",
      "Epoch 787/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4528 - accuracy: 0.7841 - val_loss: 0.5170 - val_accuracy: 0.7561\n",
      "Epoch 788/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4527 - accuracy: 0.7821 - val_loss: 0.5170 - val_accuracy: 0.7561\n",
      "Epoch 789/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4533 - accuracy: 0.7821 - val_loss: 0.5171 - val_accuracy: 0.7561\n",
      "Epoch 790/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4527 - accuracy: 0.7780 - val_loss: 0.5170 - val_accuracy: 0.7724\n",
      "Epoch 791/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4530 - accuracy: 0.7780 - val_loss: 0.5172 - val_accuracy: 0.7561\n",
      "Epoch 792/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4521 - accuracy: 0.7800 - val_loss: 0.5171 - val_accuracy: 0.7561\n",
      "Epoch 793/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4525 - accuracy: 0.7800 - val_loss: 0.5172 - val_accuracy: 0.7561\n",
      "Epoch 794/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4521 - accuracy: 0.7841 - val_loss: 0.5171 - val_accuracy: 0.7724\n",
      "Epoch 795/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4523 - accuracy: 0.7841 - val_loss: 0.5173 - val_accuracy: 0.7561\n",
      "Epoch 796/800\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4522 - accuracy: 0.7841 - val_loss: 0.5171 - val_accuracy: 0.7724\n",
      "Epoch 797/800\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4526 - accuracy: 0.7862 - val_loss: 0.5172 - val_accuracy: 0.7724\n",
      "Epoch 798/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4517 - accuracy: 0.7841 - val_loss: 0.5172 - val_accuracy: 0.7561\n",
      "Epoch 799/800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4533 - accuracy: 0.7780 - val_loss: 0.5173 - val_accuracy: 0.7561\n",
      "Epoch 800/800\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4523 - accuracy: 0.7800 - val_loss: 0.5171 - val_accuracy: 0.7642\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train, batch_size = 50, epochs = 800, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSeQV3oM7Rgb"
   },
   "source": [
    "<a id = \"cell_report\"></a>\n",
    "## 5. Experiments Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "id": "u98fWxWvS6Vn",
    "outputId": "83e33f86-1954-41b4-e60f-b9031bf30e8c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualise the training and validation loss to see if the model is overfitting\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5Sjj44w0BUi"
   },
   "source": [
    "The lines seem converged, however, they are not overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "id": "atYgBppxxb-r",
    "outputId": "b2427e0b-8c2c-4388-8c4d-117885421290"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualise the training accuracy and the validation accuracy to see if the model is overfitting \n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JnsdSSVG0HyN"
   },
   "source": [
    "This is slightly overfitting but works well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zA8iLf29zM5L",
    "outputId": "73aa5d13-ca95-47ca-d533-50b36cf7435a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1]\n",
      "[0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1.\n",
      " 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#Predictions \n",
    "prediction = model.predict(X_test)\n",
    "prediction = [1 if y>= 0.5 else 0 for y in prediction]\n",
    "print(prediction)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wAF1PLh6yWp1"
   },
   "source": [
    "The values above indicate whether the prediction is equal to the test dataset. Setting the threshold as >= 0.5, it returns 1 if the probability >= 0.5, implying the chances of the person having diabetes, otherwise, it returns 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PQJEdPfvyU6A",
    "outputId": "9c86cbbd-dd28-48f3-81e2-ea8142dd46da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.88      0.84       398\n",
      "         1.0       0.73      0.58      0.65       216\n",
      "\n",
      "    accuracy                           0.78       614\n",
      "   macro avg       0.76      0.73      0.74       614\n",
      "weighted avg       0.77      0.78      0.77       614\n",
      "\n",
      "Confusion Matrix:  \n",
      " [[352  46]\n",
      " [ 90 126]]\n",
      "\n",
      "Accuracy:  0.7785016286644951\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculating the accuracy of the training set\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "pred = model.predict(X_train)\n",
    "pred = [1 if y>= 0.5 else 0 for y in pred]\n",
    "print(classification_report(y_train, pred))\n",
    "print('Confusion Matrix:  \\n', confusion_matrix(y_train, pred))\n",
    "print()\n",
    "print('Accuracy: ', accuracy_score(y_train, pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XpyDwIcC67hF"
   },
   "source": [
    "The training accuracy is 0.77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c4pfnLXXzCKP",
    "outputId": "2421f96a-d806-4777-f06a-702659369a99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.84      0.83       102\n",
      "         1.0       0.68      0.65      0.67        52\n",
      "\n",
      "    accuracy                           0.78       154\n",
      "   macro avg       0.75      0.75      0.75       154\n",
      "weighted avg       0.78      0.78      0.78       154\n",
      "\n",
      "Confusion Matrix:  \n",
      " [[86 16]\n",
      " [18 34]]\n",
      "\n",
      "Accuracy:  0.7792207792207793\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculating the accuracy of the test set\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "pred = model.predict(X_test)\n",
    "pred = [1 if y>= 0.5 else 0 for y in pred]\n",
    "print(classification_report(y_test, pred))\n",
    "print('Confusion Matrix:  \\n', confusion_matrix(y_test, pred))\n",
    "print()\n",
    "print('Accuracy: ', accuracy_score(y_test, pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WjrwgqwFzQl6",
    "outputId": "3934c4ea-8b64-4373-ff4d-94725ed20cdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7792207598686218"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7Db-T2T0Uvt"
   },
   "source": [
    "Therefore, we can see that based on the number of neurons present in a particular layer, the accuracy differs. We can further alter the number of Dense layers as well to reach a certain test and train accuracy score. The accuracy suggests how well the model is at predicting whether a person has diabetes or not. This resolves the business problem of classification issues of diabetes. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
